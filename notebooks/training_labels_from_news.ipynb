{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-25T00:53:52.276739Z",
     "start_time": "2025-11-25T00:53:52.094016Z"
    }
   },
   "source": [
    "# ============================================================\n",
    "# TRAINING LABELS NOTEBOOK - Cell 1: Setup\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TRAINING LABELS: NEWS-TO-WARD MAPPING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load ward boundaries for reference\n",
    "wards_gdf = gpd.read_file('../data/wards/kmc_wards_gee_ready.geojson')\n",
    "wards_gdf['WARD'] = wards_gdf['WARD'].str.strip()\n",
    "print(f\"âœ… Loaded {len(wards_gdf)} wards\")\n",
    "\n",
    "# ============================================================\n",
    "# LOCALITY TO WARD MAPPING (Based on KMC Borough structure)\n",
    "# ============================================================\n",
    "\n",
    "# This mapping is based on KMC's 16 borough structure\n",
    "# Multiple wards can share a locality name\n",
    "\n",
    "LOCALITY_TO_WARDS = {\n",
    "    # VERY HIGH FREQUENCY HOTSPOTS (8+ events)\n",
    "    'Behala': ['120', '121', '122', '123', '124', '125', '126', '127', '128', '129'],\n",
    "    'Jodhpur Park': ['86', '87'],\n",
    "    'Garia': ['135', '136', '137', '138'],\n",
    "    'Kamdahari': ['137', '138'],\n",
    "    'College Street': ['44', '45', '46'],\n",
    "    'Kalighat': ['82', '83', '84'],\n",
    "\n",
    "    # HIGH FREQUENCY (5-7 events)\n",
    "    'Ballygunge': ['63', '64', '65', '66', '67'],\n",
    "    'Central Avenue': ['43', '44', '48'],\n",
    "    'Tollygunge': ['99', '100', '101', '102', '103'],\n",
    "    'Jadavpur': ['95', '96', '97', '98'],\n",
    "    'Thanthania': ['47', '48'],\n",
    "    'Salt Lake': ['106', '107', '108'],  # Note: partially outside KMC\n",
    "    'New Alipore': ['117', '118', '119'],\n",
    "    'Lake Gardens': ['88', '89', '90'],\n",
    "    'Ultadanga': ['33', '34'],\n",
    "\n",
    "    # MODERATE FREQUENCY\n",
    "    'Shyambazar': ['6', '7', '8', '9'],\n",
    "    'Lake Town': ['35', '36'],\n",
    "    'Esplanade': ['49', '50', '51'],\n",
    "    'Park Street': ['61', '62'],\n",
    "    'EM Bypass': ['105', '106', '107', '108', '109'],\n",
    "    'Kasba': ['92', '93', '94'],\n",
    "    'New Town': [],  # Outside KMC\n",
    "    'Dum Dum': ['1', '2', '3', '4', '5'],\n",
    "    'Maniktala': ['27', '28', '29'],\n",
    "    'Topsia': ['68', '69', '70'],\n",
    "    'Tangra': ['57', '58', '59'],\n",
    "    'Park Circus': ['71', '72', '73'],\n",
    "    'Bhawanipur': ['74', '75', '76'],\n",
    "    'Hazra': ['77', '78', '79'],\n",
    "    'New Market': ['52', '53'],\n",
    "    'Dharmatala': ['49', '50'],\n",
    "    'VIP Road': ['5', '6', '35'],\n",
    "    'Garden Reach': ['130', '131', '132', '133', '134'],\n",
    "    'Cossipur': ['10', '11', '12'],\n",
    "    'Regent Park': ['91'],\n",
    "    'Beliaghata': ['37', '38', '39', '40'],\n",
    "\n",
    "    # 2019 SPECIFIC WARDS (from your document)\n",
    "    'Ward_111': ['111'],\n",
    "    'Ward_114': ['114'],\n",
    "    'Ward_109': ['109'],\n",
    "    'Ward_122': ['122'],\n",
    "    'Ward_127': ['127'],\n",
    "}\n",
    "\n",
    "# Reverse mapping for lookup\n",
    "WARD_TO_LOCALITIES = {}\n",
    "for locality, wards in LOCALITY_TO_WARDS.items():\n",
    "    for ward in wards:\n",
    "        if ward not in WARD_TO_LOCALITIES:\n",
    "            WARD_TO_LOCALITIES[ward] = []\n",
    "        WARD_TO_LOCALITIES[ward].append(locality)\n",
    "\n",
    "print(f\"âœ… Mapped {len(LOCALITY_TO_WARDS)} localities to wards\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING LABELS: NEWS-TO-WARD MAPPING\n",
      "============================================================\n",
      "âœ… Loaded 141 wards\n",
      "âœ… Mapped 41 localities to wards\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T00:55:25.537014Z",
     "start_time": "2025-11-25T00:55:25.523071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# Cell 2: FLOOD EVENTS DATABASE\n",
    "# ============================================================\n",
    "\n",
    "# Structured flood events from your document\n",
    "FLOOD_EVENTS = [\n",
    "    # 2015: Cyclone Komen\n",
    "    {\n",
    "        'event_id': '2015_KOMEN',\n",
    "        'start_date': '2015-07-26',\n",
    "        'end_date': '2015-08-02',\n",
    "        'event_type': 'cyclone',\n",
    "        'max_rainfall_mm': 87,\n",
    "        'localities': ['Beliaghata', 'Central Avenue'],\n",
    "        'confidence': 0.7,  # Tier 2: News geocoded\n",
    "        'source': 'Cyclone Komen reports',\n",
    "        'notes': 'Cholera outbreak followed'\n",
    "    },\n",
    "\n",
    "    # 2017: Major July Floods\n",
    "    {\n",
    "        'event_id': '2017_JULY_FLOOD',\n",
    "        'start_date': '2017-07-20',\n",
    "        'end_date': '2017-07-26',\n",
    "        'event_type': 'monsoon',\n",
    "        'max_rainfall_mm': 142,  # 48-hour peak\n",
    "        'localities': ['Ultadanga', 'Central Avenue', 'Shyambazar', 'Garia',\n",
    "                      'Esplanade', 'Lake Town', 'Behala', 'College Street', 'EM Bypass'],\n",
    "        'confidence': 0.8,  # Tier 2: Multiple news sources\n",
    "        'source': 'Government reports, news',\n",
    "        'notes': '70+ wards inundated, 50+ deaths, â‚¹553 crore damage'\n",
    "    },\n",
    "\n",
    "    # 2018: June monsoon\n",
    "    {\n",
    "        'event_id': '2018_JUNE',\n",
    "        'start_date': '2018-06-12',\n",
    "        'end_date': '2018-06-12',\n",
    "        'event_type': 'monsoon',\n",
    "        'max_rainfall_mm': 100,  # Estimated from 419mm June total\n",
    "        'localities': ['Bhawanipur', 'Central Avenue'],\n",
    "        'confidence': 0.6,  # Tier 3: Area inference\n",
    "        'source': 'News reports',\n",
    "        'notes': 'High tide coincidence'\n",
    "    },\n",
    "\n",
    "    # 2019: August waterlogging (SPECIFIC WARDS!)\n",
    "    {\n",
    "        'event_id': '2019_AUG',\n",
    "        'start_date': '2019-08-16',\n",
    "        'end_date': '2019-08-17',\n",
    "        'event_type': 'monsoon',\n",
    "        'max_rainfall_mm': 80,  # Estimated\n",
    "        'localities': ['Ward_111', 'Ward_114', 'Ward_109', 'Ward_122', 'Ward_127'],\n",
    "        'confidence': 1.0,  # Tier 1: Ward explicit!\n",
    "        'source': 'KMC records',\n",
    "        'notes': 'Churial Canal undredged due to contractor insolvency'\n",
    "    },\n",
    "\n",
    "    # 2019: Cyclone Bulbul\n",
    "    {\n",
    "        'event_id': '2019_BULBUL',\n",
    "        'start_date': '2019-11-09',\n",
    "        'end_date': '2019-11-10',\n",
    "        'event_type': 'cyclone',\n",
    "        'max_rainfall_mm': 166,\n",
    "        'localities': ['Ballygunge'],  # Tree fall fatality location\n",
    "        'confidence': 0.7,\n",
    "        'source': 'Cyclone reports',\n",
    "        'notes': 'Wind damage primary, 1 death in Kolkata'\n",
    "    },\n",
    "\n",
    "    # 2020: CYCLONE AMPHAN (MAJOR)\n",
    "    {\n",
    "        'event_id': '2020_AMPHAN',\n",
    "        'start_date': '2020-05-20',\n",
    "        'end_date': '2020-05-21',\n",
    "        'event_type': 'cyclone',\n",
    "        'max_rainfall_mm': 236,\n",
    "        'localities': ['Behala', 'College Street', 'New Alipore', 'Salt Lake',\n",
    "                      'Ultadanga', 'Central Avenue', 'Shyambazar', 'Garia',\n",
    "                      'Esplanade', 'Lake Town', 'Regent Park', 'Ballygunge'],\n",
    "        'confidence': 0.9,  # Tier 1-2: Extensive documentation\n",
    "        'source': 'Government reports, satellite imagery',\n",
    "        'notes': 'Costliest cyclone in N Indian Ocean, 6.6 sq.km inundated, 19 deaths in Kolkata'\n",
    "    },\n",
    "\n",
    "    # 2021: Cyclone Yaas\n",
    "    {\n",
    "        'event_id': '2021_YAAS',\n",
    "        'start_date': '2021-05-26',\n",
    "        'end_date': '2021-05-27',\n",
    "        'event_type': 'cyclone',\n",
    "        'max_rainfall_mm': 90,  # Estimated\n",
    "        'localities': ['Behala', 'Garden Reach'],  # Coastal areas\n",
    "        'confidence': 0.6,\n",
    "        'source': 'Cyclone reports',\n",
    "        'notes': 'Landfall in Odisha, less impact on Kolkata proper'\n",
    "    },\n",
    "\n",
    "    # 2021: September monsoon\n",
    "    {\n",
    "        'event_id': '2021_SEP',\n",
    "        'start_date': '2021-09-20',\n",
    "        'end_date': '2021-09-21',\n",
    "        'event_type': 'monsoon',\n",
    "        'max_rainfall_mm': 142,\n",
    "        'localities': ['Salt Lake', 'College Street', 'Central Avenue', 'Kalighat'],\n",
    "        'confidence': 0.8,\n",
    "        'source': 'IMD data, news',\n",
    "        'notes': 'Heaviest September rain since 2007, 24-30h waterlogging'\n",
    "    },\n",
    "\n",
    "    # 2023: August flooding\n",
    "    {\n",
    "        'event_id': '2023_AUG',\n",
    "        'start_date': '2023-08-15',\n",
    "        'end_date': '2023-08-17',\n",
    "        'event_type': 'monsoon',\n",
    "        'max_rainfall_mm': 191,\n",
    "        'localities': ['Tollygunge', 'Behala', 'Jadavpur', 'Garia'],\n",
    "        'confidence': 0.7,\n",
    "        'source': 'News reports',\n",
    "        'notes': 'South/southwest Kolkata most affected, 48h+ waterlogging'\n",
    "    },\n",
    "\n",
    "    # 2024: Cyclone Remal\n",
    "    {\n",
    "        'event_id': '2024_REMAL',\n",
    "        'start_date': '2024-05-26',\n",
    "        'end_date': '2024-05-27',\n",
    "        'event_type': 'cyclone',\n",
    "        'max_rainfall_mm': 260,\n",
    "        'localities': ['Park Street', 'Esplanade'],  # Metro stations flooded\n",
    "        'confidence': 0.8,\n",
    "        'source': 'News, metro reports',\n",
    "        'notes': 'Metro tunnels flooded, 294 trees uprooted'\n",
    "    },\n",
    "\n",
    "    # 2024: Cyclone Dana aftermath\n",
    "    {\n",
    "        'event_id': '2024_DANA',\n",
    "        'start_date': '2024-10-25',\n",
    "        'end_date': '2024-10-26',\n",
    "        'event_type': 'cyclone',\n",
    "        'max_rainfall_mm': 190,  # Jodhpur Park\n",
    "        'localities': ['Bhawanipur', 'New Market', 'Hazra', 'Dharmatala', 'Behala',\n",
    "                      'Jodhpur Park', 'Lake Gardens', 'Kalighat', 'Thanthania',\n",
    "                      'VIP Road', 'Park Circus', 'Dum Dum'],\n",
    "        'confidence': 0.8,\n",
    "        'source': 'News reports',\n",
    "        'notes': '2 electrocution deaths, knee-deep flooding'\n",
    "    },\n",
    "\n",
    "    # 2025: July event\n",
    "    {\n",
    "        'event_id': '2025_JULY',\n",
    "        'start_date': '2025-07-08',\n",
    "        'end_date': '2025-07-08',\n",
    "        'event_type': 'monsoon',\n",
    "        'max_rainfall_mm': 195,  # Jodhpur Park\n",
    "        'localities': ['Jodhpur Park', 'Dum Dum', 'Salt Lake', 'Maniktala',\n",
    "                      'Thanthania', 'Central Avenue', 'College Street', 'Kasba',\n",
    "                      'Tollygunge', 'Garia', 'Jadavpur', 'Behala', 'EM Bypass'],\n",
    "        'confidence': 0.8,\n",
    "        'source': 'IMD, news',\n",
    "        'notes': 'Orange alert for 5 south Bengal districts'\n",
    "    },\n",
    "\n",
    "    # 2025: SEPTEMBER CLOUDBURST (MOST SEVERE NON-CYCLONE)\n",
    "    {\n",
    "        'event_id': '2025_SEP_CLOUDBURST',\n",
    "        'start_date': '2025-09-23',\n",
    "        'end_date': '2025-09-25',\n",
    "        'event_type': 'cloudburst',\n",
    "        'max_rainfall_mm': 332,  # Garia Kamdahari\n",
    "        'localities': ['Garia', 'Kamdahari', 'Jodhpur Park', 'Kalighat', 'Topsia',\n",
    "                      'Ballygunge', 'Jadavpur', 'Behala', 'Tollygunge'],\n",
    "        'confidence': 0.9,\n",
    "        'source': 'IMD, news, fatality reports',\n",
    "        'notes': '6th highest rainfall in 137 years, 11-12 deaths, Ballygunge pump failure'\n",
    "    },\n",
    "]\n",
    "\n",
    "print(f\"âœ… Defined {len(FLOOD_EVENTS)} flood events\")"
   ],
   "id": "427128c3d8ce22e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Defined 13 flood events\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T00:56:04.358307Z",
     "start_time": "2025-11-25T00:56:04.333413Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# Cell 3: GENERATE WARD-LEVEL LABELS\n",
    "# ============================================================\n",
    "\n",
    "def expand_event_to_wards(event, locality_mapping):\n",
    "    \"\"\"Expand a flood event to individual ward-date labels\"\"\"\n",
    "    labels = []\n",
    "\n",
    "    # Get all affected wards\n",
    "    affected_wards = set()\n",
    "    for locality in event['localities']:\n",
    "        if locality in locality_mapping:\n",
    "            affected_wards.update(locality_mapping[locality])\n",
    "\n",
    "    # Generate date range\n",
    "    start = pd.to_datetime(event['start_date'])\n",
    "    end = pd.to_datetime(event['end_date'])\n",
    "    dates = pd.date_range(start, end, freq='D')\n",
    "\n",
    "    # Create labels for each ward-date combination\n",
    "    for date in dates:\n",
    "        for ward in affected_wards:\n",
    "            labels.append({\n",
    "                'date': date.strftime('%Y-%m-%d'),\n",
    "                'ward_id': ward,\n",
    "                'flooded': 1,\n",
    "                'event_id': event['event_id'],\n",
    "                'event_type': event['event_type'],\n",
    "                'confidence': event['confidence'],\n",
    "                'max_rainfall_mm': event['max_rainfall_mm'],\n",
    "                'source': event['source'],\n",
    "                'notes': event['notes']\n",
    "            })\n",
    "\n",
    "    return labels\n",
    "\n",
    "# Generate all labels\n",
    "all_labels = []\n",
    "for event in FLOOD_EVENTS:\n",
    "    event_labels = expand_event_to_wards(event, LOCALITY_TO_WARDS)\n",
    "    all_labels.extend(event_labels)\n",
    "    print(f\"  {event['event_id']}: {len(event_labels)} ward-date labels\")\n",
    "\n",
    "df_flood_labels = pd.DataFrame(all_labels)\n",
    "\n",
    "print(f\"\\nâœ… FLOOD LABELS GENERATED\")\n",
    "print(f\"   Total positive labels: {len(df_flood_labels)}\")\n",
    "print(f\"   Unique dates: {df_flood_labels['date'].nunique()}\")\n",
    "print(f\"   Unique wards: {df_flood_labels['ward_id'].nunique()}\")\n",
    "\n",
    "# Summary by event\n",
    "print(\"\\nðŸ“Š LABELS BY EVENT:\")\n",
    "print(df_flood_labels.groupby('event_id').size().sort_values(ascending=False))"
   ],
   "id": "d91bae037403c366",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2015_KOMEN: 56 ward-date labels\n",
      "  2017_JULY_FLOOD: 245 ward-date labels\n",
      "  2018_JUNE: 6 ward-date labels\n",
      "  2019_AUG: 10 ward-date labels\n",
      "  2019_BULBUL: 10 ward-date labels\n",
      "  2020_AMPHAN: 84 ward-date labels\n",
      "  2021_YAAS: 30 ward-date labels\n",
      "  2021_SEP: 22 ward-date labels\n",
      "  2023_AUG: 69 ward-date labels\n",
      "  2024_REMAL: 10 ward-date labels\n",
      "  2024_DANA: 80 ward-date labels\n",
      "  2025_JULY: 47 ward-date labels\n",
      "  2025_SEP_CLOUDBURST: 108 ward-date labels\n",
      "\n",
      "âœ… FLOOD LABELS GENERATED\n",
      "   Total positive labels: 777\n",
      "   Unique dates: 37\n",
      "   Unique wards: 100\n",
      "\n",
      "ðŸ“Š LABELS BY EVENT:\n",
      "event_id\n",
      "2017_JULY_FLOOD        245\n",
      "2025_SEP_CLOUDBURST    108\n",
      "2020_AMPHAN             84\n",
      "2024_DANA               80\n",
      "2023_AUG                69\n",
      "2015_KOMEN              56\n",
      "2025_JULY               47\n",
      "2021_YAAS               30\n",
      "2021_SEP                22\n",
      "2019_AUG                10\n",
      "2019_BULBUL             10\n",
      "2024_REMAL              10\n",
      "2018_JUNE                6\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T00:56:33.317865Z",
     "start_time": "2025-11-25T00:56:32.504283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# Cell 4: ADD NEGATIVE LABELS (Non-flood days)\n",
    "# ============================================================\n",
    "\n",
    "# Get all ward IDs\n",
    "all_wards = [str(i) for i in range(1, 142)]\n",
    "\n",
    "# Get all dates from precipitation features\n",
    "precip_dates = pd.read_csv(\n",
    "    '../data/processed/precipitation_features_2014_2025.csv',\n",
    "    usecols=['date']\n",
    ")['date'].unique()\n",
    "\n",
    "print(f\"Total dates available: {len(precip_dates)}\")\n",
    "\n",
    "# Identify flood dates\n",
    "flood_dates = set(df_flood_labels['date'].unique())\n",
    "print(f\"Flood dates: {len(flood_dates)}\")\n",
    "\n",
    "# Sample negative labels (dry season + low-rainfall monsoon days)\n",
    "# Strategy: 3:1 ratio of negatives to positives for balanced training\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# Get dates with low rainfall (< 20mm) that aren't flood events\n",
    "precip_df = pd.read_csv('../data/processed/precipitation_features_2014_2025.csv')\n",
    "precip_df['date'] = pd.to_datetime(precip_df['date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# City-wide daily average\n",
    "daily_avg = precip_df.groupby('date')['rain_d0'].mean().reset_index()\n",
    "low_rain_dates = daily_avg[daily_avg['rain_d0'] < 20]['date'].values\n",
    "\n",
    "# Exclude flood dates\n",
    "safe_dates = [d for d in low_rain_dates if d not in flood_dates]\n",
    "print(f\"Safe non-flood dates (< 20mm rain): {len(safe_dates)}\")\n",
    "\n",
    "# Sample negative labels\n",
    "n_positives = len(df_flood_labels)\n",
    "n_negatives_needed = n_positives * 3  # 3:1 ratio\n",
    "\n",
    "# Sample dates and wards\n",
    "negative_labels = []\n",
    "dates_per_sample = n_negatives_needed // len(all_wards) + 1\n",
    "sampled_dates = np.random.choice(safe_dates, size=min(dates_per_sample, len(safe_dates)), replace=False)\n",
    "\n",
    "for date in sampled_dates:\n",
    "    for ward in all_wards:\n",
    "        negative_labels.append({\n",
    "            'date': date,\n",
    "            'ward_id': ward,\n",
    "            'flooded': 0,\n",
    "            'event_id': 'NO_FLOOD',\n",
    "            'event_type': 'none',\n",
    "            'confidence': 0.9,  # High confidence for dry days\n",
    "            'max_rainfall_mm': 0,\n",
    "            'source': 'GPM verification',\n",
    "            'notes': 'Low rainfall day'\n",
    "        })\n",
    "\n",
    "df_negative = pd.DataFrame(negative_labels)\n",
    "\n",
    "# Combine\n",
    "df_all_labels = pd.concat([df_flood_labels, df_negative], ignore_index=True)\n",
    "\n",
    "print(f\"\\nâœ… COMPLETE TRAINING LABELS\")\n",
    "print(f\"   Positive (flooded): {len(df_flood_labels)}\")\n",
    "print(f\"   Negative (no flood): {len(df_negative)}\")\n",
    "print(f\"   Total: {len(df_all_labels)}\")\n",
    "print(f\"   Class ratio: 1:{len(df_negative)//len(df_flood_labels)}\")"
   ],
   "id": "d6cd191055c5ff11",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dates available: 4346\n",
      "Flood dates: 37\n",
      "Safe non-flood dates (< 20mm rain): 3711\n",
      "\n",
      "âœ… COMPLETE TRAINING LABELS\n",
      "   Positive (flooded): 777\n",
      "   Negative (no flood): 2397\n",
      "   Total: 3174\n",
      "   Class ratio: 1:3\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T00:56:51.296081Z",
     "start_time": "2025-11-25T00:56:51.276855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# Cell 5: SAVE AND SUMMARIZE\n",
    "# ============================================================\n",
    "\n",
    "# Save labels\n",
    "OUTPUT_PATH = Path('../data/processed/training_labels_v1.csv')\n",
    "df_all_labels.to_csv(OUTPUT_PATH, index=False)\n",
    "print(f\"âœ… Saved: {OUTPUT_PATH}\")\n",
    "\n",
    "# Also save just flood events for reference\n",
    "df_flood_labels.to_csv('../data/processed/flood_events_positive_labels.csv', index=False)\n",
    "print(f\"âœ… Saved: flood_events_positive_labels.csv\")\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ðŸ“Š TRAINING LABELS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nðŸŽ¯ BY CONFIDENCE TIER:\")\n",
    "print(df_flood_labels.groupby('confidence').size())\n",
    "\n",
    "print(\"\\nðŸŽ¯ BY EVENT TYPE:\")\n",
    "print(df_flood_labels.groupby('event_type').size())\n",
    "\n",
    "print(\"\\nðŸŽ¯ TOP 10 MOST FLOODED WARDS:\")\n",
    "ward_counts = df_flood_labels['ward_id'].value_counts().head(10)\n",
    "print(ward_counts)\n",
    "\n",
    "print(\"\\nðŸŽ¯ TEMPORAL DISTRIBUTION:\")\n",
    "df_flood_labels['year'] = pd.to_datetime(df_flood_labels['date']).dt.year\n",
    "print(df_flood_labels.groupby('year').size())"
   ],
   "id": "c6799af2fadadd52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved: ../data/processed/training_labels_v1.csv\n",
      "âœ… Saved: flood_events_positive_labels.csv\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š TRAINING LABELS SUMMARY\n",
      "============================================================\n",
      "\n",
      "ðŸŽ¯ BY CONFIDENCE TIER:\n",
      "confidence\n",
      "0.6     36\n",
      "0.7    135\n",
      "0.8    404\n",
      "0.9    192\n",
      "1.0     10\n",
      "dtype: int64\n",
      "\n",
      "ðŸŽ¯ BY EVENT TYPE:\n",
      "event_type\n",
      "cloudburst    108\n",
      "cyclone       270\n",
      "monsoon       399\n",
      "dtype: int64\n",
      "\n",
      "ðŸŽ¯ TOP 10 MOST FLOODED WARDS:\n",
      "ward_id\n",
      "48     23\n",
      "122    22\n",
      "127    22\n",
      "43     21\n",
      "44     21\n",
      "120    20\n",
      "129    20\n",
      "123    20\n",
      "124    20\n",
      "128    20\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ðŸŽ¯ TEMPORAL DISTRIBUTION:\n",
      "year\n",
      "2015     56\n",
      "2017    245\n",
      "2018      6\n",
      "2019     20\n",
      "2020     84\n",
      "2021     52\n",
      "2023     69\n",
      "2024     90\n",
      "2025    155\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T03:43:48.386408Z",
     "start_time": "2025-11-25T03:43:47.514811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# Cell 6: PHYSICS-BASED LABEL EXPANSION\n",
    "# ============================================================\n",
    "\n",
    "# Load precipitation features\n",
    "precip_df = pd.read_csv('../data/processed/precipitation_features_2014_2025.csv')\n",
    "precip_df['date'] = pd.to_datetime(precip_df['date'])\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"PHYSICS-BASED LABEL EXPANSION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# KMC Drainage Capacity Threshold\n",
    "DRAINAGE_CAPACITY_MM = 150  # 6mm/hour Ã— 24 hours\n",
    "\n",
    "# CHRONIC HOTSPOTS (from your document - flood in 5+ events)\n",
    "CHRONIC_WARDS = {\n",
    "    # Very High Frequency (8+ events)\n",
    "    'Behala': ['120', '121', '122', '123', '124', '125', '126', '127', '128', '129'],\n",
    "    'Jodhpur Park': ['86', '87'],\n",
    "    'Garia': ['135', '136', '137', '138'],\n",
    "    'College Street': ['44', '45', '46'],\n",
    "    'Kalighat': ['82', '83', '84'],\n",
    "\n",
    "    # High Frequency (5-7 events)\n",
    "    'Ballygunge': ['63', '64', '65', '66', '67'],\n",
    "    'Central Avenue': ['43', '44', '48'],\n",
    "    'Tollygunge': ['99', '100', '101', '102', '103'],\n",
    "    'Jadavpur': ['95', '96', '97', '98'],\n",
    "    'Thanthania': ['47', '48'],\n",
    "    'Salt Lake': ['106', '107', '108'],\n",
    "    'New Alipore': ['117', '118', '119'],\n",
    "    'Lake Gardens': ['88', '89', '90'],\n",
    "    'Ultadanga': ['33', '34'],\n",
    "    'Tangra-Topsia': ['57', '58', '59', '68', '69', '70'],\n",
    "}\n",
    "\n",
    "# Flatten to set of chronic ward IDs\n",
    "chronic_ward_ids = set()\n",
    "for wards in CHRONIC_WARDS.values():\n",
    "    chronic_ward_ids.update(wards)\n",
    "\n",
    "print(f\"Chronic hotspot wards: {len(chronic_ward_ids)}\")\n",
    "\n",
    "# ============================================================\n",
    "# RULE 1: Heavy rain (>150mm) + Chronic ward = FLOODED\n",
    "# ============================================================\n",
    "\n",
    "# Find days where city average exceeded drainage capacity\n",
    "daily_city_avg = precip_df.groupby('date')['rain_d0'].mean().reset_index()\n",
    "heavy_rain_dates = daily_city_avg[daily_city_avg['rain_d0'] >= DRAINAGE_CAPACITY_MM]['date']\n",
    "\n",
    "print(f\"\\nDays exceeding {DRAINAGE_CAPACITY_MM}mm threshold: {len(heavy_rain_dates)}\")\n",
    "\n",
    "# Generate labels for chronic wards on heavy rain days\n",
    "physics_labels_heavy = []\n",
    "for date in heavy_rain_dates:\n",
    "    date_str = date.strftime('%Y-%m-%d')\n",
    "    for ward in chronic_ward_ids:\n",
    "        physics_labels_heavy.append({\n",
    "            'date': date_str,\n",
    "            'ward_id': ward,\n",
    "            'flooded': 1,\n",
    "            'event_id': f'PHYSICS_HEAVY_{date_str}',\n",
    "            'event_type': 'physics_inferred',\n",
    "            'confidence': 0.7,  # High confidence - physics threshold\n",
    "            'max_rainfall_mm': daily_city_avg[daily_city_avg['date'] == date]['rain_d0'].values[0],\n",
    "            'source': 'Physics threshold + chronic hotspot',\n",
    "            'notes': f'Rain exceeded {DRAINAGE_CAPACITY_MM}mm drainage capacity'\n",
    "        })\n",
    "\n",
    "print(f\"Rule 1 (Heavy + Chronic): {len(physics_labels_heavy)} labels\")\n",
    "\n",
    "# ============================================================\n",
    "# RULE 2: Moderate rain (>100mm) + Very High Frequency wards = FLOODED\n",
    "# ============================================================\n",
    "\n",
    "VERY_HIGH_FREQ_WARDS = set()\n",
    "for locality in ['Behala', 'Jodhpur Park', 'Garia', 'College Street', 'Kalighat']:\n",
    "    VERY_HIGH_FREQ_WARDS.update(CHRONIC_WARDS[locality])\n",
    "\n",
    "moderate_rain_dates = daily_city_avg[\n",
    "    (daily_city_avg['rain_d0'] >= 100) &\n",
    "    (daily_city_avg['rain_d0'] < DRAINAGE_CAPACITY_MM)\n",
    "]['date']\n",
    "\n",
    "print(f\"Days with 100-150mm: {len(moderate_rain_dates)}\")\n",
    "\n",
    "physics_labels_moderate = []\n",
    "for date in moderate_rain_dates:\n",
    "    date_str = date.strftime('%Y-%m-%d')\n",
    "    for ward in VERY_HIGH_FREQ_WARDS:\n",
    "        physics_labels_moderate.append({\n",
    "            'date': date_str,\n",
    "            'ward_id': ward,\n",
    "            'flooded': 1,\n",
    "            'event_id': f'PHYSICS_MODERATE_{date_str}',\n",
    "            'event_type': 'physics_inferred',\n",
    "            'confidence': 0.5,  # Lower confidence\n",
    "            'max_rainfall_mm': daily_city_avg[daily_city_avg['date'] == date]['rain_d0'].values[0],\n",
    "            'source': 'Moderate rain + very high frequency hotspot',\n",
    "            'notes': 'Rain 100-150mm in historically vulnerable ward'\n",
    "        })\n",
    "\n",
    "print(f\"Rule 2 (Moderate + VeryHigh): {len(physics_labels_moderate)} labels\")\n",
    "\n",
    "# ============================================================\n",
    "# RULE 3: 7-day accumulation > 400mm = Saturated ground flooding\n",
    "# ============================================================\n",
    "\n",
    "# Check 7-day accumulation\n",
    "daily_7day = precip_df.groupby('date')['rain_7day'].mean().reset_index()\n",
    "saturated_dates = daily_7day[daily_7day['rain_7day'] >= 400]['date']\n",
    "\n",
    "print(f\"Days with 7-day accumulation > 400mm: {len(saturated_dates)}\")\n",
    "\n",
    "physics_labels_saturated = []\n",
    "for date in saturated_dates:\n",
    "    date_str = date.strftime('%Y-%m-%d')\n",
    "    # Only very high frequency wards for saturation flooding\n",
    "    for ward in VERY_HIGH_FREQ_WARDS:\n",
    "        physics_labels_saturated.append({\n",
    "            'date': date_str,\n",
    "            'ward_id': ward,\n",
    "            'flooded': 1,\n",
    "            'event_id': f'PHYSICS_SATURATED_{date_str}',\n",
    "            'event_type': 'physics_inferred',\n",
    "            'confidence': 0.4,  # Lower confidence - indirect indicator\n",
    "            'max_rainfall_mm': daily_7day[daily_7day['date'] == date]['rain_7day'].values[0],\n",
    "            'source': 'Ground saturation inference',\n",
    "            'notes': '7-day accumulation exceeded 400mm'\n",
    "        })\n",
    "\n",
    "print(f\"Rule 3 (Saturation): {len(physics_labels_saturated)} labels\")"
   ],
   "id": "5f812cc3c8ec66bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PHYSICS-BASED LABEL EXPANSION\n",
      "============================================================\n",
      "Chronic hotspot wards: 56\n",
      "\n",
      "Days exceeding 150mm threshold: 13\n",
      "Rule 1 (Heavy + Chronic): 728 labels\n",
      "Days with 100-150mm: 48\n",
      "Rule 2 (Moderate + VeryHigh): 1056 labels\n",
      "Days with 7-day accumulation > 400mm: 47\n",
      "Rule 3 (Saturation): 1034 labels\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T03:44:47.428541Z",
     "start_time": "2025-11-25T03:44:47.386433Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# Cell 7: COMBINE ALL LABELS\n",
    "# ============================================================\n",
    "\n",
    "# Load existing news-based labels\n",
    "df_news = pd.read_csv('../data/processed/flood_events_positive_labels.csv')\n",
    "df_news['date'] = pd.to_datetime(df_news['date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Combine physics-based labels\n",
    "df_physics = pd.concat([\n",
    "    pd.DataFrame(physics_labels_heavy),\n",
    "    pd.DataFrame(physics_labels_moderate),\n",
    "    pd.DataFrame(physics_labels_saturated)\n",
    "], ignore_index=True)\n",
    "\n",
    "# Merge, keeping higher confidence when duplicates exist\n",
    "df_all_positive = pd.concat([df_news, df_physics], ignore_index=True)\n",
    "\n",
    "# Remove duplicates, keeping highest confidence\n",
    "df_all_positive = df_all_positive.sort_values('confidence', ascending=False)\n",
    "df_all_positive = df_all_positive.drop_duplicates(subset=['date', 'ward_id'], keep='first')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ðŸ“Š EXPANDED POSITIVE LABELS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nNews-based labels: {len(df_news)}\")\n",
    "print(f\"Physics-based labels: {len(df_physics)}\")\n",
    "print(f\"Combined (deduplicated): {len(df_all_positive)}\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ BY SOURCE:\")\n",
    "print(df_all_positive['source'].value_counts())\n",
    "\n",
    "print(\"\\nðŸŽ¯ BY CONFIDENCE:\")\n",
    "print(df_all_positive['confidence'].value_counts().sort_index())\n",
    "\n",
    "print(\"\\nðŸŽ¯ BY YEAR:\")\n",
    "df_all_positive['year'] = pd.to_datetime(df_all_positive['date']).dt.year\n",
    "print(df_all_positive.groupby('year').size())"
   ],
   "id": "6658b1dbc3859ba4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ðŸ“Š EXPANDED POSITIVE LABELS\n",
      "============================================================\n",
      "\n",
      "News-based labels: 777\n",
      "Physics-based labels: 2818\n",
      "Combined (deduplicated): 3441\n",
      "\n",
      "ðŸŽ¯ BY SOURCE:\n",
      "source\n",
      "Moderate rain + very high frequency hotspot    1056\n",
      "Ground saturation inference                     880\n",
      "Physics threshold + chronic hotspot             728\n",
      "Government reports, news                        245\n",
      "News reports                                    155\n",
      "IMD, news, fatality reports                     108\n",
      "Government reports, satellite imagery            84\n",
      "Cyclone Komen reports                            56\n",
      "IMD, news                                        47\n",
      "Cyclone reports                                  40\n",
      "IMD data, news                                   22\n",
      "KMC records                                      10\n",
      "News, metro reports                              10\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ðŸŽ¯ BY CONFIDENCE:\n",
      "confidence\n",
      "0.4     880\n",
      "0.5    1056\n",
      "0.6      36\n",
      "0.7     863\n",
      "0.8     404\n",
      "0.9     192\n",
      "1.0      10\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ðŸŽ¯ BY YEAR:\n",
      "year\n",
      "2014    122\n",
      "2015    420\n",
      "2016    188\n",
      "2017    555\n",
      "2018    116\n",
      "2019    230\n",
      "2020    216\n",
      "2021    694\n",
      "2022     44\n",
      "2023    135\n",
      "2024    466\n",
      "2025    255\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T03:45:55.299274Z",
     "start_time": "2025-11-25T03:45:54.546925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# Cell 8: CREATE BALANCED TRAINING SET\n",
    "# ============================================================\n",
    "\n",
    "# Load precipitation for negative sampling\n",
    "precip_df = pd.read_csv('../data/processed/precipitation_features_2014_2025.csv')\n",
    "precip_df['date'] = pd.to_datetime(precip_df['date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Get all flood dates\n",
    "flood_dates = set(df_all_positive['date'].unique())\n",
    "\n",
    "# Sample negatives: dry season days + low rainfall monsoon days\n",
    "daily_avg = precip_df.groupby('date')['rain_d0'].mean().reset_index()\n",
    "\n",
    "# Very safe negatives: < 10mm rain and NOT a flood date\n",
    "very_safe_dates = daily_avg[\n",
    "    (daily_avg['rain_d0'] < 10) &\n",
    "    (~daily_avg['date'].isin(flood_dates))\n",
    "]['date'].values\n",
    "\n",
    "print(f\"Very safe negative dates (<10mm, no flood): {len(very_safe_dates)}\")\n",
    "\n",
    "# Sample for balance (2:1 negative:positive ratio)\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "n_positives = len(df_all_positive)\n",
    "n_neg_dates_needed = (n_positives * 2) // 141 + 1  # Divide by wards\n",
    "\n",
    "sampled_neg_dates = np.random.choice(\n",
    "    very_safe_dates,\n",
    "    size=min(n_neg_dates_needed, len(very_safe_dates)),\n",
    "    replace=False\n",
    ")\n",
    "\n",
    "# Generate negative labels for ALL wards on safe dates\n",
    "all_wards = [str(i) for i in range(1, 142)]\n",
    "negative_labels = []\n",
    "\n",
    "for date in sampled_neg_dates:\n",
    "    for ward in all_wards:\n",
    "        negative_labels.append({\n",
    "            'date': date,\n",
    "            'ward_id': ward,\n",
    "            'flooded': 0,\n",
    "            'event_id': 'NO_FLOOD',\n",
    "            'event_type': 'none',\n",
    "            'confidence': 0.95,\n",
    "            'max_rainfall_mm': 0,\n",
    "            'source': 'Dry day verification',\n",
    "            'notes': f'Rain < 10mm'\n",
    "        })\n",
    "\n",
    "df_negative = pd.DataFrame(negative_labels)\n",
    "\n",
    "# Combine final dataset\n",
    "df_training = pd.concat([df_all_positive, df_negative], ignore_index=True)\n",
    "\n",
    "print(f\"\\nâœ… FINAL TRAINING SET\")\n",
    "print(f\"   Positive (flooded): {len(df_all_positive)}\")\n",
    "print(f\"   Negative (no flood): {len(df_negative)}\")\n",
    "print(f\"   Total: {len(df_training)}\")\n",
    "print(f\"   Class ratio: 1:{len(df_negative)//len(df_all_positive):.1f}\")\n",
    "\n",
    "# Save\n",
    "df_training.to_csv('../data/processed/training_labels_v2_physics.csv', index=False)\n",
    "df_all_positive.to_csv('../data/processed/flood_events_positive_v2.csv', index=False)\n",
    "\n",
    "print(f\"\\nâœ… Saved: training_labels_v2_physics.csv\")\n",
    "print(f\"âœ… Saved: flood_events_positive_v2.csv\")"
   ],
   "id": "e2573a9188b0ca6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Very safe negative dates (<10mm, no flood): 3362\n",
      "\n",
      "âœ… FINAL TRAINING SET\n",
      "   Positive (flooded): 3441\n",
      "   Negative (no flood): 6909\n",
      "   Total: 10350\n",
      "   Class ratio: 1:2.0\n",
      "\n",
      "âœ… Saved: training_labels_v2_physics.csv\n",
      "âœ… Saved: flood_events_positive_v2.csv\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T03:47:57.185884Z",
     "start_time": "2025-11-25T03:47:56.494645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# THRESHOLD VALIDATION: What rainfall actually caused flooding?\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "precip_df = pd.read_csv('../data/processed/precipitation_features_2014_2025.csv')\n",
    "precip_df['date'] = pd.to_datetime(precip_df['date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "news_labels = pd.read_csv('../data/processed/flood_events_positive_labels.csv')\n",
    "\n",
    "# Get unique flood dates from NEWS (verified events)\n",
    "news_flood_dates = news_labels['date'].unique()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"RAINFALL ON VERIFIED FLOOD DAYS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# City-wide average rainfall on flood days\n",
    "daily_avg = precip_df.groupby('date').agg({\n",
    "    'rain_d0': 'mean',\n",
    "    'rain_d1': 'mean',\n",
    "    'rain_d2': 'mean',\n",
    "    'rain_d3': 'mean',\n",
    "    'rain_7day': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "flood_day_rain = daily_avg[daily_avg['date'].isin(news_flood_dates)].copy()\n",
    "flood_day_rain = flood_day_rain.sort_values('rain_d0', ascending=False)\n",
    "\n",
    "print(f\"\\nðŸ“Š VERIFIED FLOOD DAYS ({len(flood_day_rain)} days):\")\n",
    "print(flood_day_rain[['date', 'rain_d0', 'rain_7day']].head(20).to_string(index=False))\n",
    "\n",
    "print(f\"\\nðŸ“ˆ RAINFALL STATISTICS ON FLOOD DAYS:\")\n",
    "print(f\"   Same-day (rain_d0):\")\n",
    "print(f\"      Min:    {flood_day_rain['rain_d0'].min():.1f} mm\")\n",
    "print(f\"      25%:    {flood_day_rain['rain_d0'].quantile(0.25):.1f} mm\")\n",
    "print(f\"      Median: {flood_day_rain['rain_d0'].median():.1f} mm\")\n",
    "print(f\"      75%:    {flood_day_rain['rain_d0'].quantile(0.75):.1f} mm\")\n",
    "print(f\"      Max:    {flood_day_rain['rain_d0'].max():.1f} mm\")\n",
    "\n",
    "print(f\"\\n   7-day accumulation:\")\n",
    "print(f\"      Min:    {flood_day_rain['rain_7day'].min():.1f} mm\")\n",
    "print(f\"      Median: {flood_day_rain['rain_7day'].median():.1f} mm\")\n",
    "print(f\"      Max:    {flood_day_rain['rain_7day'].max():.1f} mm\")"
   ],
   "id": "da3f6c6789ec0511",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RAINFALL ON VERIFIED FLOOD DAYS\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š VERIFIED FLOOD DAYS (37 days):\n",
      "      date    rain_d0  rain_7day\n",
      "2024-10-25 222.644533 314.753822\n",
      "2019-11-09 160.317585 237.189072\n",
      "2021-09-20 151.738224 594.295164\n",
      "2017-07-23 150.850565 398.857084\n",
      "2019-08-16 123.110423 386.146941\n",
      "2015-08-01 122.958323 354.835198\n",
      "2019-08-17 122.675458 503.460910\n",
      "2020-05-20 117.894536 155.420280\n",
      "2015-07-31 108.891487 321.409780\n",
      "2017-07-22 102.069856 249.158080\n",
      "2024-05-26  65.606453 114.891770\n",
      "2024-05-27  61.734396 135.709997\n",
      "2017-07-24  59.853261 458.002118\n",
      "2025-09-25  56.573119 317.455666\n",
      "2025-07-08  56.220283 217.221697\n",
      "2015-07-29  51.688723 285.899000\n",
      "2018-06-12  45.388864 157.680776\n",
      "2017-07-20  41.082694 155.964678\n",
      "2023-08-17  39.455176 162.833046\n",
      "2015-08-02  36.803049 380.270729\n",
      "\n",
      "ðŸ“ˆ RAINFALL STATISTICS ON FLOOD DAYS:\n",
      "   Same-day (rain_d0):\n",
      "      Min:    0.0 mm\n",
      "      25%:    14.9 mm\n",
      "      Median: 39.5 mm\n",
      "      75%:    102.1 mm\n",
      "      Max:    222.6 mm\n",
      "\n",
      "   7-day accumulation:\n",
      "      Min:    59.6 mm\n",
      "      Median: 277.3 mm\n",
      "      Max:    594.3 mm\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T03:49:13.589586Z",
     "start_time": "2025-11-25T03:49:13.576899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# FIND THE TRUE THRESHOLD\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"THRESHOLD ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# What % of flood days had rainfall above various thresholds?\n",
    "thresholds = [50, 75, 100, 125, 150, 175, 200]\n",
    "\n",
    "print(\"\\nðŸŽ¯ SAME-DAY RAINFALL (rain_d0):\")\n",
    "for thresh in thresholds:\n",
    "    pct = (flood_day_rain['rain_d0'] >= thresh).mean() * 100\n",
    "    count = (flood_day_rain['rain_d0'] >= thresh).sum()\n",
    "    print(f\"   >= {thresh:3d}mm: {pct:5.1f}% ({count}/{len(flood_day_rain)} days)\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ BUT WAIT - What about lagged rainfall?\")\n",
    "# Check if floods occurred with LOW same-day but HIGH previous days\n",
    "low_sameday_floods = flood_day_rain[flood_day_rain['rain_d0'] < 50]\n",
    "print(f\"\\nFlood days with < 50mm same-day rain: {len(low_sameday_floods)}\")\n",
    "if len(low_sameday_floods) > 0:\n",
    "    print(low_sameday_floods[['date', 'rain_d0', 'rain_d1', 'rain_d2', 'rain_d3', 'rain_7day']].to_string(index=False))"
   ],
   "id": "2a2dda3584cb8417",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "THRESHOLD ANALYSIS\n",
      "============================================================\n",
      "\n",
      "ðŸŽ¯ SAME-DAY RAINFALL (rain_d0):\n",
      "   >=  50mm:  43.2% (16/37 days)\n",
      "   >=  75mm:  27.0% (10/37 days)\n",
      "   >= 100mm:  27.0% (10/37 days)\n",
      "   >= 125mm:  10.8% (4/37 days)\n",
      "   >= 150mm:  10.8% (4/37 days)\n",
      "   >= 175mm:   2.7% (1/37 days)\n",
      "   >= 200mm:   2.7% (1/37 days)\n",
      "\n",
      "ðŸŽ¯ BUT WAIT - What about lagged rainfall?\n",
      "\n",
      "Flood days with < 50mm same-day rain: 21\n",
      "      date   rain_d0    rain_d1    rain_d2    rain_d3  rain_7day\n",
      "2018-06-12 45.388864  18.991134  24.674397  23.777304 157.680776\n",
      "2017-07-20 41.082694  77.265105   2.754752   0.708227 155.964678\n",
      "2023-08-17 39.455176  20.795602  17.682127   0.310993 162.833046\n",
      "2015-08-02 36.803049 122.958323 108.891487  26.215532 380.270729\n",
      "2017-07-25 35.572623  59.853261 150.850565 102.069856 490.819989\n",
      "2021-05-27 31.657943  14.923049  11.651205  25.341772  91.301062\n",
      "2015-07-30 26.215532  51.688723  13.301205  20.412411 287.604603\n",
      "2017-07-21 24.125886  41.082694  77.265105   2.754752 155.455174\n",
      "2023-08-16 20.795602  17.682127   0.310993  14.235673 128.393614\n",
      "2015-07-27 20.412411  11.367518  89.532905  75.086310 300.154248\n",
      "2023-08-15 17.682127   0.310993  14.235673  50.534467 108.345388\n",
      "2021-05-26 14.923049  11.651205  25.341772   7.727092  59.643119\n",
      "2015-07-28 13.301205  20.412411  11.367518  89.532905 277.308574\n",
      "2015-07-26 11.367518  89.532905  75.086310  24.509929 349.958431\n",
      "2025-09-23 11.135461  69.752622   8.235319 161.311202 268.221199\n",
      "2021-09-21  9.330922 151.738224 112.569004  45.807091 385.887013\n",
      "2017-07-26  7.114113  35.572623  59.853261 150.850565 420.668998\n",
      "2025-09-24  4.523688  11.135461  69.752622   8.235319 261.935667\n",
      "2019-11-10  0.777021 160.317585  74.446665   0.425248 237.966093\n",
      "2024-10-26  0.000000 222.644533  40.694183  36.645106 299.983822\n",
      "2020-05-21  0.000000 117.894536  30.131134   1.956312 152.499216\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T03:49:59.182663Z",
     "start_time": "2025-11-25T03:49:59.163914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# COMPARE: FLOOD DAYS vs NON-FLOOD DAYS\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FLOOD vs NON-FLOOD DAY COMPARISON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "non_flood_days = daily_avg[~daily_avg['date'].isin(news_flood_dates)]\n",
    "\n",
    "print(f\"\\nðŸ“Š Rainfall Distribution:\")\n",
    "print(f\"{'Metric':<20} {'Flood Days':>15} {'Non-Flood Days':>15}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Count':<20} {len(flood_day_rain):>15} {len(non_flood_days):>15}\")\n",
    "print(f\"{'Mean rain_d0':<20} {flood_day_rain['rain_d0'].mean():>15.1f} {non_flood_days['rain_d0'].mean():>15.1f}\")\n",
    "print(f\"{'Median rain_d0':<20} {flood_day_rain['rain_d0'].median():>15.1f} {non_flood_days['rain_d0'].median():>15.1f}\")\n",
    "print(f\"{'Mean rain_7day':<20} {flood_day_rain['rain_7day'].mean():>15.1f} {non_flood_days['rain_7day'].mean():>15.1f}\")\n",
    "\n",
    "# How many non-flood days had HIGH rainfall? (potential missed floods)\n",
    "print(f\"\\nâš ï¸ NON-FLOOD DAYS WITH HIGH RAINFALL (potential gaps):\")\n",
    "high_rain_non_flood = non_flood_days[non_flood_days['rain_d0'] >= 100]\n",
    "print(f\"   Days with >= 100mm but NO flood label: {len(high_rain_non_flood)}\")\n",
    "high_rain_non_flood_150 = non_flood_days[non_flood_days['rain_d0'] >= 150]\n",
    "print(f\"   Days with >= 150mm but NO flood label: {len(high_rain_non_flood_150)}\")\n",
    "\n",
    "if len(high_rain_non_flood_150) > 0:\n",
    "    print(\"\\n   These dates likely had unreported flooding:\")\n",
    "    print(high_rain_non_flood_150[['date', 'rain_d0', 'rain_7day']].head(10).to_string(index=False))"
   ],
   "id": "bfc52c65393687bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FLOOD vs NON-FLOOD DAY COMPARISON\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š Rainfall Distribution:\n",
      "Metric                    Flood Days  Non-Flood Days\n",
      "--------------------------------------------------\n",
      "Count                             37            4309\n",
      "Mean rain_d0                    58.0             8.9\n",
      "Median rain_d0                  39.5             0.1\n",
      "Mean rain_7day                 275.1            63.7\n",
      "\n",
      "âš ï¸ NON-FLOOD DAYS WITH HIGH RAINFALL (potential gaps):\n",
      "   Days with >= 100mm but NO flood label: 51\n",
      "   Days with >= 150mm but NO flood label: 9\n",
      "\n",
      "   These dates likely had unreported flooding:\n",
      "      date    rain_d0  rain_7day\n",
      "2014-09-20 205.684534 223.705952\n",
      "2015-07-09 216.035030 417.721976\n",
      "2016-08-21 224.634889 307.646447\n",
      "2017-06-19 169.701839 187.558931\n",
      "2021-07-01 204.315414 307.451014\n",
      "2021-07-29 298.747795 574.776796\n",
      "2021-09-14 217.739073 303.120419\n",
      "2024-05-06 163.297939 164.664109\n",
      "2025-09-20 161.311202 285.521695\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T03:53:34.898682Z",
     "start_time": "2025-11-25T03:53:33.237050Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# Cell: DATA-DRIVEN PHYSICS RULES\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DATA-DRIVEN FLOOD LABELING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load data\n",
    "precip_df = pd.read_csv('../data/processed/precipitation_features_2014_2025.csv')\n",
    "precip_df['date'] = pd.to_datetime(precip_df['date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Load existing news labels\n",
    "news_labels = pd.read_csv('../data/processed/flood_events_positive_labels.csv')\n",
    "news_flood_dates = set(news_labels['date'].unique())\n",
    "\n",
    "# City-wide daily stats\n",
    "daily_avg = precip_df.groupby('date').agg({\n",
    "    'rain_d0': 'mean',\n",
    "    'rain_d1': 'mean',\n",
    "    'rain_d2': 'mean',\n",
    "    'rain_d3': 'mean',\n",
    "    'rain_7day': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# ============================================================\n",
    "# EMPIRICAL THRESHOLDS (from your flood day statistics)\n",
    "# ============================================================\n",
    "\n",
    "# From your data:\n",
    "# - Flood day 7-day median: 277mm, 25th percentile: ~160mm\n",
    "# - Non-flood day 7-day mean: 64mm\n",
    "# - Clear separation around 200-250mm 7-day accumulation\n",
    "\n",
    "RULE_THRESHOLDS = {\n",
    "    'heavy_sameday': 150,      # Drainage capacity (engineering limit)\n",
    "    'moderate_sameday': 100,   # Still significant\n",
    "    'heavy_7day': 250,         # Above flood-day median\n",
    "    'moderate_7day': 200,      # Between distributions\n",
    "    'heavy_lag': 100,          # Significant prior-day rain\n",
    "}\n",
    "\n",
    "# Chronic wards (from document)\n",
    "VERY_HIGH_FREQ_WARDS = set()\n",
    "for locality in ['Behala', 'Jodhpur Park', 'Garia', 'College Street', 'Kalighat']:\n",
    "    VERY_HIGH_FREQ_WARDS.update({\n",
    "        '120', '121', '122', '123', '124', '125', '126', '127', '128', '129',  # Behala\n",
    "        '86', '87',  # Jodhpur Park\n",
    "        '135', '136', '137', '138',  # Garia\n",
    "        '44', '45', '46',  # College Street\n",
    "        '82', '83', '84',  # Kalighat\n",
    "    })\n",
    "\n",
    "HIGH_FREQ_WARDS = VERY_HIGH_FREQ_WARDS.union({\n",
    "    '63', '64', '65', '66', '67',  # Ballygunge\n",
    "    '43', '48',  # Central Avenue\n",
    "    '99', '100', '101', '102', '103',  # Tollygunge\n",
    "    '95', '96', '97', '98',  # Jadavpur\n",
    "    '33', '34',  # Ultadanga\n",
    "})\n",
    "\n",
    "print(f\"Very high frequency wards: {len(VERY_HIGH_FREQ_WARDS)}\")\n",
    "print(f\"High frequency wards: {len(HIGH_FREQ_WARDS)}\")\n",
    "\n",
    "# ============================================================\n",
    "# RULE 1: Heavy same-day (â‰¥150mm) - ANY ward floods\n",
    "# Engineering certainty: drainage capacity exceeded\n",
    "# ============================================================\n",
    "\n",
    "rule1_dates = daily_avg[daily_avg['rain_d0'] >= RULE_THRESHOLDS['heavy_sameday']]['date'].values\n",
    "print(f\"\\nRule 1 dates (â‰¥150mm same-day): {len(rule1_dates)}\")\n",
    "\n",
    "rule1_labels = []\n",
    "all_wards = [str(i) for i in range(1, 142)]\n",
    "\n",
    "for date in rule1_dates:\n",
    "    if date not in news_flood_dates:  # Don't duplicate\n",
    "        # All chronic wards flood when drainage exceeded\n",
    "        for ward in HIGH_FREQ_WARDS:\n",
    "            rule1_labels.append({\n",
    "                'date': date,\n",
    "                'ward_id': ward,\n",
    "                'flooded': 1,\n",
    "                'event_id': f'PHYSICS_R1_{date}',\n",
    "                'event_type': 'physics_drainage_exceeded',\n",
    "                'confidence': 0.85,\n",
    "                'source': 'Drainage capacity exceeded (â‰¥150mm)',\n",
    "                'notes': f\"Same-day: {daily_avg[daily_avg['date']==date]['rain_d0'].values[0]:.0f}mm\"\n",
    "            })\n",
    "\n",
    "print(f\"Rule 1 labels: {len(rule1_labels)}\")\n",
    "\n",
    "# ============================================================\n",
    "# RULE 2: High 7-day accumulation (â‰¥250mm) + chronic ward\n",
    "# Empirical: median flood-day accumulation\n",
    "# ============================================================\n",
    "\n",
    "rule2_dates = daily_avg[\n",
    "    (daily_avg['rain_7day'] >= RULE_THRESHOLDS['heavy_7day']) &\n",
    "    (~daily_avg['date'].isin(news_flood_dates)) &\n",
    "    (~daily_avg['date'].isin(rule1_dates))\n",
    "]['date'].values\n",
    "\n",
    "print(f\"Rule 2 dates (â‰¥250mm 7-day, not in R1): {len(rule2_dates)}\")\n",
    "\n",
    "rule2_labels = []\n",
    "for date in rule2_dates:\n",
    "    for ward in VERY_HIGH_FREQ_WARDS:\n",
    "        rule2_labels.append({\n",
    "            'date': date,\n",
    "            'ward_id': ward,\n",
    "            'flooded': 1,\n",
    "            'event_id': f'PHYSICS_R2_{date}',\n",
    "            'event_type': 'physics_saturation',\n",
    "            'confidence': 0.7,\n",
    "            'source': '7-day accumulation â‰¥250mm + chronic ward',\n",
    "            'notes': f\"7-day: {daily_avg[daily_avg['date']==date]['rain_7day'].values[0]:.0f}mm\"\n",
    "        })\n",
    "\n",
    "print(f\"Rule 2 labels: {len(rule2_labels)}\")\n",
    "\n",
    "# ============================================================\n",
    "# RULE 3: Lag effect - Heavy rain 1-3 days ago + chronic ward\n",
    "# Empirical: Sep 23, Oct 26 pattern\n",
    "# ============================================================\n",
    "\n",
    "# Find days where PREVIOUS days had heavy rain but same-day is low\n",
    "daily_avg['max_lag'] = daily_avg[['rain_d1', 'rain_d2', 'rain_d3']].max(axis=1)\n",
    "\n",
    "rule3_dates = daily_avg[\n",
    "    (daily_avg['rain_d0'] < 50) &  # Low same-day\n",
    "    (daily_avg['max_lag'] >= RULE_THRESHOLDS['heavy_lag']) &  # Heavy recent\n",
    "    (daily_avg['rain_7day'] >= RULE_THRESHOLDS['moderate_7day']) &  # Accumulated\n",
    "    (~daily_avg['date'].isin(news_flood_dates)) &\n",
    "    (~daily_avg['date'].isin(rule1_dates)) &\n",
    "    (~daily_avg['date'].isin(rule2_dates))\n",
    "]['date'].values\n",
    "\n",
    "print(f\"Rule 3 dates (lag effect): {len(rule3_dates)}\")\n",
    "\n",
    "rule3_labels = []\n",
    "for date in rule3_dates:\n",
    "    for ward in VERY_HIGH_FREQ_WARDS:\n",
    "        row = daily_avg[daily_avg['date'] == date].iloc[0]\n",
    "        rule3_labels.append({\n",
    "            'date': date,\n",
    "            'ward_id': ward,\n",
    "            'flooded': 1,\n",
    "            'event_id': f'PHYSICS_R3_{date}',\n",
    "            'event_type': 'physics_lag_effect',\n",
    "            'confidence': 0.6,\n",
    "            'source': 'Lag effect (heavy rain 1-3 days prior)',\n",
    "            'notes': f\"Same-day: {row['rain_d0']:.0f}mm, Max lag: {row['max_lag']:.0f}mm\"\n",
    "        })\n",
    "\n",
    "print(f\"Rule 3 labels: {len(rule3_labels)}\")"
   ],
   "id": "6db541771883dca4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATA-DRIVEN FLOOD LABELING\n",
      "============================================================\n",
      "Very high frequency wards: 22\n",
      "High frequency wards: 40\n",
      "\n",
      "Rule 1 dates (â‰¥150mm same-day): 13\n",
      "Rule 1 labels: 360\n",
      "Rule 2 dates (â‰¥250mm 7-day, not in R1): 205\n",
      "Rule 2 labels: 4510\n",
      "Rule 3 dates (lag effect): 25\n",
      "Rule 3 labels: 550\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T03:53:48.691653Z",
     "start_time": "2025-11-25T03:53:48.666838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# Cell: COMBINE AND VALIDATE\n",
    "# ============================================================\n",
    "\n",
    "# Combine all physics labels\n",
    "df_physics = pd.concat([\n",
    "    pd.DataFrame(rule1_labels),\n",
    "    pd.DataFrame(rule2_labels),\n",
    "    pd.DataFrame(rule3_labels)\n",
    "], ignore_index=True)\n",
    "\n",
    "# Load news labels\n",
    "df_news = pd.read_csv('../data/processed/flood_events_positive_labels.csv')\n",
    "\n",
    "# Combine\n",
    "df_all_positive = pd.concat([df_news, df_physics], ignore_index=True)\n",
    "df_all_positive = df_all_positive.sort_values('confidence', ascending=False)\n",
    "df_all_positive = df_all_positive.drop_duplicates(subset=['date', 'ward_id'], keep='first')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ðŸ“Š FINAL POSITIVE LABELS (DATA-DRIVEN)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nâœ… News-based: {len(df_news)}\")\n",
    "print(f\"âœ… Rule 1 (drainage exceeded): {len(rule1_labels)}\")\n",
    "print(f\"âœ… Rule 2 (7-day saturation): {len(rule2_labels)}\")\n",
    "print(f\"âœ… Rule 3 (lag effect): {len(rule3_labels)}\")\n",
    "print(f\"âœ… Total (deduplicated): {len(df_all_positive)}\")\n",
    "\n",
    "print(\"\\nðŸŽ¯ BY SOURCE:\")\n",
    "print(df_all_positive['source'].value_counts())\n",
    "\n",
    "print(\"\\nðŸŽ¯ BY CONFIDENCE:\")\n",
    "print(df_all_positive['confidence'].value_counts().sort_index())\n",
    "\n",
    "# Validate: Check if we captured the 9 missing high-rain days\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âš ï¸ VALIDATION: Did we capture the missing 150mm+ days?\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "missing_dates = [\n",
    "    '2014-09-20', '2015-07-09', '2016-08-21', '2017-06-19',\n",
    "    '2021-07-01', '2021-07-29', '2021-09-14', '2024-05-06', '2025-09-20'\n",
    "]\n",
    "\n",
    "physics_dates = set(df_all_positive['date'].unique())\n",
    "for date in missing_dates:\n",
    "    status = \"âœ… CAPTURED\" if date in physics_dates else \"âŒ MISSING\"\n",
    "    rain = daily_avg[daily_avg['date'] == date]['rain_d0'].values\n",
    "    rain_str = f\"{rain[0]:.0f}mm\" if len(rain) > 0 else \"N/A\"\n",
    "    print(f\"   {date}: {rain_str} - {status}\")"
   ],
   "id": "6987b196ecf0d72c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ðŸ“Š FINAL POSITIVE LABELS (DATA-DRIVEN)\n",
      "============================================================\n",
      "\n",
      "âœ… News-based: 777\n",
      "âœ… Rule 1 (drainage exceeded): 360\n",
      "âœ… Rule 2 (7-day saturation): 4510\n",
      "âœ… Rule 3 (lag effect): 550\n",
      "âœ… Total (deduplicated): 6197\n",
      "\n",
      "ðŸŽ¯ BY SOURCE:\n",
      "source\n",
      "7-day accumulation â‰¥250mm + chronic ward    4510\n",
      "Lag effect (heavy rain 1-3 days prior)       550\n",
      "Drainage capacity exceeded (â‰¥150mm)          360\n",
      "Government reports, news                     245\n",
      "News reports                                 155\n",
      "IMD, news, fatality reports                  108\n",
      "Government reports, satellite imagery         84\n",
      "Cyclone Komen reports                         56\n",
      "IMD, news                                     47\n",
      "Cyclone reports                               40\n",
      "IMD data, news                                22\n",
      "KMC records                                   10\n",
      "News, metro reports                           10\n",
      "Name: count, dtype: int64\n",
      "\n",
      "ðŸŽ¯ BY CONFIDENCE:\n",
      "confidence\n",
      "0.60     586\n",
      "0.70    4645\n",
      "0.80     404\n",
      "0.85     360\n",
      "0.90     192\n",
      "1.00      10\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "âš ï¸ VALIDATION: Did we capture the missing 150mm+ days?\n",
      "============================================================\n",
      "   2014-09-20: 206mm - âœ… CAPTURED\n",
      "   2015-07-09: 216mm - âœ… CAPTURED\n",
      "   2016-08-21: 225mm - âœ… CAPTURED\n",
      "   2017-06-19: 170mm - âœ… CAPTURED\n",
      "   2021-07-01: 204mm - âœ… CAPTURED\n",
      "   2021-07-29: 299mm - âœ… CAPTURED\n",
      "   2021-09-14: 218mm - âœ… CAPTURED\n",
      "   2024-05-06: 163mm - âœ… CAPTURED\n",
      "   2025-09-20: 161mm - âœ… CAPTURED\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-25T03:54:13.133035Z",
     "start_time": "2025-11-25T03:54:13.062765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ============================================================\n",
    "# Cell: CREATE BALANCED TRAINING SET\n",
    "# ============================================================\n",
    "\n",
    "# Safe negatives: low rain AND low accumulation\n",
    "safe_neg_dates = daily_avg[\n",
    "    (daily_avg['rain_d0'] < 10) &\n",
    "    (daily_avg['rain_7day'] < 100) &\n",
    "    (~daily_avg['date'].isin(df_all_positive['date'].unique()))\n",
    "]['date'].values\n",
    "\n",
    "print(f\"\\nSafe negative dates: {len(safe_neg_dates)}\")\n",
    "\n",
    "# Sample for 2:1 ratio\n",
    "np.random.seed(42)\n",
    "n_pos = len(df_all_positive)\n",
    "n_neg_dates = (n_pos * 2) // 141 + 1\n",
    "\n",
    "sampled_dates = np.random.choice(safe_neg_dates, size=min(n_neg_dates, len(safe_neg_dates)), replace=False)\n",
    "\n",
    "negative_labels = []\n",
    "all_wards = [str(i) for i in range(1, 142)]\n",
    "\n",
    "for date in sampled_dates:\n",
    "    for ward in all_wards:\n",
    "        negative_labels.append({\n",
    "            'date': date,\n",
    "            'ward_id': ward,\n",
    "            'flooded': 0,\n",
    "            'event_id': 'NO_FLOOD',\n",
    "            'event_type': 'none',\n",
    "            'confidence': 0.95,\n",
    "            'source': 'Verified dry (<10mm, <100mm 7-day)',\n",
    "            'notes': ''\n",
    "        })\n",
    "\n",
    "df_negative = pd.DataFrame(negative_labels)\n",
    "df_training = pd.concat([df_all_positive, df_negative], ignore_index=True)\n",
    "\n",
    "print(f\"\\nâœ… FINAL TRAINING SET (DATA-DRIVEN)\")\n",
    "print(f\"   Positive: {len(df_all_positive)}\")\n",
    "print(f\"   Negative: {len(df_negative)}\")\n",
    "print(f\"   Total: {len(df_training)}\")\n",
    "print(f\"   Ratio: 1:{len(df_negative)/len(df_all_positive):.1f}\")\n",
    "\n",
    "# Save\n",
    "df_training.to_csv('../data/processed/training_labels_v3_empirical.csv', index=False)\n",
    "df_all_positive.to_csv('../data/processed/flood_events_positive_v3.csv', index=False)\n",
    "\n",
    "print(f\"\\nâœ… Saved: training_labels_v3_empirical.csv\")\n",
    "print(f\"âœ… Saved: flood_events_positive_v3.csv\")"
   ],
   "id": "8c429c138ece97a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Safe negative dates: 2877\n",
      "\n",
      "âœ… FINAL TRAINING SET (DATA-DRIVEN)\n",
      "   Positive: 6197\n",
      "   Negative: 12408\n",
      "   Total: 18605\n",
      "   Ratio: 1:2.0\n",
      "\n",
      "âœ… Saved: training_labels_v3_empirical.csv\n",
      "âœ… Saved: flood_events_positive_v3.csv\n"
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
