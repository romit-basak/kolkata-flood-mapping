{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa835773-625d-4ae4-a35e-47474aa1b951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "KOLKATA FLOOD PREDICTION - FEATURE ENGINEERING\n",
      "============================================================\n",
      "\n",
      "1. Loading data assets...\n",
      "   Loading FABDEM ward statistics...\n",
      "   ✓ Loaded 141 wards\n",
      "   ✓ Identified 5 wetland interface wards\n",
      "   Loading historical flood events...\n",
      "   ✓ Loaded 184 flood records\n",
      "   ✓ Date range: 2023-09-02 to 2025-10-10\n",
      "\n",
      "2. Processing rainfall data...\n",
      "   Extracting rainfall statistics per ward...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/kolkata_flood/lib/python3.13/site-packages/rasterstats/io.py:335: NodataWarning: Setting nodata to -999; specify nodata explicitly\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ✓ Added rainfall statistics for 4 months\n",
      "\n",
      "3. Creating training dataset...\n",
      "   ✓ Created 1128 training samples\n",
      "\n",
      "4. Data quality check...\n",
      "   Class balance: 9.2% positive (flooded)\n",
      "   Flood events: 104\n",
      "   Non-flood events: 1024\n",
      "\n",
      "5. Feature importance (correlation with flooding):\n",
      "--------------------------------------------------\n",
      "   rainfall_mean            : +0.138\n",
      "   rainfall_max             : +0.137\n",
      "   flow_log                 : +0.131\n",
      "   elevation_range          : +0.055\n",
      "   flow_max                 : +0.038\n",
      "   is_wetland_interface     : +0.022\n",
      "   flow_mean                : +0.005\n",
      "   elevation_mean           : -0.072\n",
      "   elevation_min            : -0.085\n",
      "\n",
      "6. High-risk ward analysis...\n",
      "\n",
      "   Top 10 most frequently flooded wards:\n",
      "   Ward 130: 87.5% flood rate\n",
      "   Ward  68: 87.5% flood rate\n",
      "   Ward  93: 87.5% flood rate\n",
      "   Ward  66: 75.0% flood rate\n",
      "   Ward  65: 75.0% flood rate\n",
      "   Ward  73: 62.5% flood rate\n",
      "   Ward  96: 62.5% flood rate\n",
      "   Ward  91: 62.5% flood rate\n",
      "   Ward  99: 62.5% flood rate\n",
      "   Ward  63: 62.5% flood rate\n",
      "\n",
      "   Ward 109 Special Analysis (Extreme Flow Zone):\n",
      "   - Flow accumulation: 85,685 (legitimate - wetland drainage)\n",
      "   - Elevation: 1.86m (lowest in city)\n",
      "   - Flood rate: 0.0%\n",
      "\n",
      "7. Saving processed data...\n",
      "   ✓ Saved training data: ../data/processed/ml_training_data.csv\n",
      "   ✓ Saved feature matrix: 9 features\n",
      "   ✓ Saved ward static features\n",
      "\n",
      "============================================================\n",
      "FEATURE ENGINEERING COMPLETE\n",
      "============================================================\n",
      "\n",
      "Summary:\n",
      "- Total samples: 1,128\n",
      "- Unique dates: 8\n",
      "- Unique wards: 141\n",
      "- Features: 9\n",
      "- Target balance: 9.2% positive\n",
      "\n",
      "Ready for:\n",
      "1. Baseline ML model (Random Forest)\n",
      "2. Satellite data integration \n",
      "3. Deep learning model training\n",
      "\n",
      "Next step: Run notebook 09_sentinel_extraction.ipynb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# notebooks/07_feature_engineering.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterstats import zonal_stats\n",
    "from datetime import datetime\n",
    "from abc import ABC, abstractmethod\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"KOLKATA FLOOD PREDICTION - FEATURE ENGINEERING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================\n",
    "# MODULAR DATA SOURCE DESIGN\n",
    "# ============================================\n",
    "\n",
    "class FloodDataSource(ABC):\n",
    "    \"\"\"Abstract base class for flood data sources\"\"\"\n",
    "    @abstractmethod\n",
    "    def get_flood_labels(self, date_range=None):\n",
    "        pass\n",
    "\n",
    "class NewsBasedFloodData(FloodDataSource):\n",
    "    \"\"\"Current implementation using news-validated floods\"\"\"\n",
    "    def __init__(self, csv_path):\n",
    "        self.csv_path = csv_path\n",
    "    \n",
    "    def get_flood_labels(self, date_range=None):\n",
    "        df = pd.read_csv(self.csv_path)\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        if date_range:\n",
    "            df = df[(df['date'] >= date_range[0]) & (df['date'] <= date_range[1])]\n",
    "        return df\n",
    "\n",
    "class SatelliteFloodData(FloodDataSource):\n",
    "    \"\"\"Future implementation using Sentinel-2\"\"\"\n",
    "    def get_flood_labels(self, date_range=None):\n",
    "        # TODO: Implement satellite-based flood detection\n",
    "        raise NotImplementedError(\"Satellite integration coming in next phase!\")\n",
    "\n",
    "# ============================================\n",
    "# DATA LOADING\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n1. Loading data assets...\")\n",
    "\n",
    "# Initialize flood data source\n",
    "flood_source = NewsBasedFloodData('../data/processed/kolkata_flood_events_2023_2025.csv')\n",
    "\n",
    "# Load FABDEM-processed ward statistics\n",
    "print(\"   Loading FABDEM ward statistics...\")\n",
    "wards = gpd.read_file('../data/processed/kolkata_wards_fabdem_complete.gpkg')\n",
    "\n",
    "# Clean ward IDs\n",
    "wards['WARD'] = wards['WARD'].str.replace('\\n', '').astype(int)\n",
    "\n",
    "# Add log-transformed flow for better ML scaling\n",
    "wards['flow_log'] = np.log10(wards['flow_fabdem_max'] + 1)\n",
    "\n",
    "# Flag wetland interface zones (legitimate extreme flow)\n",
    "wetland_interface_wards = [109, 108, 58, 107, 127]\n",
    "wards['is_wetland_interface'] = wards['WARD'].isin(wetland_interface_wards).astype(int)\n",
    "\n",
    "print(f\"   ✓ Loaded {len(wards)} wards\")\n",
    "print(f\"   ✓ Identified {sum(wards['is_wetland_interface'])} wetland interface wards\")\n",
    "\n",
    "# Load flood events\n",
    "print(\"   Loading historical flood events...\")\n",
    "flood_events = flood_source.get_flood_labels()\n",
    "print(f\"   ✓ Loaded {len(flood_events)} flood records\")\n",
    "print(f\"   ✓ Date range: {flood_events['date'].min().date()} to {flood_events['date'].max().date()}\")\n",
    "\n",
    "# ============================================\n",
    "# RAINFALL DATA EXTRACTION\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n2. Processing rainfall data...\")\n",
    "\n",
    "# Check if rainfall file exists\n",
    "rainfall_path = Path('../data/rainfall/kolkata_rainfall_2025_monsoon.tif')\n",
    "\n",
    "if rainfall_path.exists():\n",
    "    print(\"   Extracting rainfall statistics per ward...\")\n",
    "    \n",
    "    # Extract stats for each monsoon month\n",
    "    rain_stats = {}\n",
    "    for band, month in enumerate(['june', 'july', 'aug', 'sept'], 1):\n",
    "        stats = zonal_stats(\n",
    "            wards.geometry, \n",
    "            str(rainfall_path), \n",
    "            band=band, \n",
    "            stats=['mean', 'max', 'std']\n",
    "        )\n",
    "        rain_stats[f'rain_{month}_mean'] = [s['mean'] if s else 0 for s in stats]\n",
    "        rain_stats[f'rain_{month}_max'] = [s['max'] if s else 0 for s in stats]\n",
    "        rain_stats[f'rain_{month}_std'] = [s['std'] if s else 0 for s in stats]\n",
    "    \n",
    "    # Add to ward dataframe\n",
    "    for col, values in rain_stats.items():\n",
    "        wards[col] = values\n",
    "    \n",
    "    print(\"   ✓ Added rainfall statistics for 4 months\")\n",
    "else:\n",
    "    print(\"   ⚠ Rainfall file not found. Using synthetic data for now.\")\n",
    "    for month in ['june', 'july', 'aug', 'sept']:\n",
    "        wards[f'rain_{month}_mean'] = np.random.uniform(200, 800, len(wards))\n",
    "        wards[f'rain_{month}_max'] = np.random.uniform(300, 900, len(wards))\n",
    "        wards[f'rain_{month}_std'] = np.random.uniform(50, 150, len(wards))\n",
    "\n",
    "# ============================================\n",
    "# CREATE ML TRAINING DATASET\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n3. Creating training dataset...\")\n",
    "\n",
    "training_samples = []\n",
    "\n",
    "# For each flood event\n",
    "for event_date in flood_events['date'].unique():\n",
    "    event_floods = flood_events[flood_events['date'] == event_date]\n",
    "    flooded_wards = set(event_floods[event_floods['flooded'] == 1]['ward'].values)\n",
    "    \n",
    "    # Map to appropriate rainfall month\n",
    "    month_map = {5: 'may', 6: 'june', 7: 'july', 8: 'aug', 9: 'sept', 10: 'oct'}\n",
    "    rain_month = month_map.get(event_date.month, 'sept')\n",
    "    \n",
    "    # Create sample for each ward\n",
    "    for _, ward in wards.iterrows():\n",
    "        ward_id = ward['WARD']\n",
    "        \n",
    "        # Build feature vector - NO MANUAL WEIGHTS!\n",
    "        sample = {\n",
    "            # Identifiers\n",
    "            'ward_id': ward_id,\n",
    "            'date': event_date,\n",
    "            'year': event_date.year,\n",
    "            'month': event_date.month,\n",
    "            \n",
    "            # Elevation features (FABDEM)\n",
    "            'elevation_mean': ward.get('elev_fabdem_mean', 0),\n",
    "            'elevation_min': ward.get('elev_fabdem_min', 0),\n",
    "            'elevation_max': ward.get('elev_fabdem_max', 0),\n",
    "            'elevation_range': ward.get('elev_fabdem_max', 0) - ward.get('elev_fabdem_min', 0),\n",
    "            \n",
    "            # Flow accumulation features\n",
    "            'flow_max': ward.get('flow_fabdem_max', 0),\n",
    "            'flow_mean': ward.get('flow_fabdem_mean', 0),\n",
    "            'flow_sum': ward.get('flow_fabdem_sum', 0),\n",
    "            'flow_log': ward.get('flow_log', 0),  # Log-scaled for ML\n",
    "            \n",
    "            # Rainfall features\n",
    "            'rainfall_mean': ward.get(f'rain_{rain_month}_mean', 0),\n",
    "            'rainfall_max': ward.get(f'rain_{rain_month}_max', 0),\n",
    "            'rainfall_std': ward.get(f'rain_{rain_month}_std', 0),\n",
    "            \n",
    "            # Special flags\n",
    "            'is_wetland_interface': ward.get('is_wetland_interface', 0),\n",
    "            \n",
    "            # Target variable\n",
    "            'flooded': 1 if ward_id in flooded_wards else 0\n",
    "        }\n",
    "        training_samples.append(sample)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(training_samples)\n",
    "print(f\"   ✓ Created {len(df)} training samples\")\n",
    "\n",
    "# ============================================\n",
    "# DATA QUALITY ANALYSIS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n4. Data quality check...\")\n",
    "\n",
    "# Class balance\n",
    "flood_rate = df['flooded'].mean()\n",
    "print(f\"   Class balance: {flood_rate:.1%} positive (flooded)\")\n",
    "print(f\"   Flood events: {df['flooded'].sum()}\")\n",
    "print(f\"   Non-flood events: {(df['flooded'] == 0).sum()}\")\n",
    "\n",
    "# Feature correlations with flooding\n",
    "print(\"\\n5. Feature importance (correlation with flooding):\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "feature_cols = [\n",
    "    'elevation_mean', 'elevation_min', 'elevation_range',\n",
    "    'flow_max', 'flow_mean', 'flow_log',\n",
    "    'rainfall_mean', 'rainfall_max',\n",
    "    'is_wetland_interface'\n",
    "]\n",
    "\n",
    "correlations = df[feature_cols + ['flooded']].corr()['flooded'].sort_values(ascending=False)\n",
    "for feat, corr in correlations.items():\n",
    "    if feat != 'flooded':\n",
    "        print(f\"   {feat:25s}: {corr:+.3f}\")\n",
    "\n",
    "# ============================================\n",
    "# SPECIAL ANALYSIS: HIGH-RISK WARDS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n6. High-risk ward analysis...\")\n",
    "\n",
    "# Wards that flood most frequently\n",
    "flood_frequency = df.groupby('ward_id')['flooded'].mean().sort_values(ascending=False)\n",
    "print(\"\\n   Top 10 most frequently flooded wards:\")\n",
    "for ward, freq in flood_frequency.head(10).items():\n",
    "    special_note = \" [Wetland Interface]\" if ward in wetland_interface_wards else \"\"\n",
    "    print(f\"   Ward {ward:3d}: {freq:5.1%} flood rate{special_note}\")\n",
    "\n",
    "# Ward 109 special analysis (extreme flow accumulation)\n",
    "ward_109_data = df[df['ward_id'] == 109]\n",
    "if not ward_109_data.empty:\n",
    "    print(\"\\n   Ward 109 Special Analysis (Extreme Flow Zone):\")\n",
    "    print(f\"   - Flow accumulation: {ward_109_data['flow_max'].iloc[0]:,.0f} (legitimate - wetland drainage)\")\n",
    "    print(f\"   - Elevation: {ward_109_data['elevation_mean'].iloc[0]:.2f}m (lowest in city)\")\n",
    "    print(f\"   - Flood rate: {ward_109_data['flooded'].mean():.1%}\")\n",
    "\n",
    "# ============================================\n",
    "# SAVE DATASETS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n7. Saving processed data...\")\n",
    "\n",
    "# Save full training dataset\n",
    "output_path = '../data/processed/ml_training_data.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"   ✓ Saved training data: {output_path}\")\n",
    "\n",
    "# Save feature matrix only (for ML modeling)\n",
    "feature_matrix = df[feature_cols + ['flooded', 'ward_id', 'date']]\n",
    "feature_matrix.to_csv('../data/processed/feature_matrix.csv', index=False)\n",
    "print(f\"   ✓ Saved feature matrix: {len(feature_cols)} features\")\n",
    "\n",
    "# Save ward static features for predictions\n",
    "ward_features = wards[['WARD', 'elev_fabdem_mean', 'elev_fabdem_min', \n",
    "                       'flow_fabdem_max', 'flow_fabdem_mean', 'flow_log',\n",
    "                       'is_wetland_interface']]\n",
    "ward_features.to_csv('../data/processed/ward_static_features.csv', index=False)\n",
    "print(f\"   ✓ Saved ward static features\")\n",
    "\n",
    "# ============================================\n",
    "# SUMMARY STATISTICS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE ENGINEERING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\"\"\n",
    "Summary:\n",
    "- Total samples: {len(df):,}\n",
    "- Unique dates: {df['date'].nunique()}\n",
    "- Unique wards: {df['ward_id'].nunique()}\n",
    "- Features: {len(feature_cols)}\n",
    "- Target balance: {flood_rate:.1%} positive\n",
    "\n",
    "Ready for:\n",
    "1. Baseline ML model (Random Forest)\n",
    "2. Satellite data integration \n",
    "3. Deep learning model training\n",
    "\n",
    "Next step: Run notebook 09_sentinel_extraction.ipynb\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "876b805c-12de-48bb-84fc-14e562b22a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rasterstats\n",
      "  Downloading rasterstats-0.20.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: affine in /opt/homebrew/Caskroom/miniforge/base/envs/kolkata_flood/lib/python3.13/site-packages (from rasterstats) (2.4.0)\n",
      "Requirement already satisfied: click>7.1 in /opt/homebrew/Caskroom/miniforge/base/envs/kolkata_flood/lib/python3.13/site-packages (from rasterstats) (8.3.0)\n",
      "Requirement already satisfied: cligj>=0.4 in /opt/homebrew/Caskroom/miniforge/base/envs/kolkata_flood/lib/python3.13/site-packages (from rasterstats) (0.7.2)\n",
      "Collecting fiona (from rasterstats)\n",
      "  Downloading fiona-1.10.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (56 kB)\n",
      "Requirement already satisfied: numpy>=1.9 in /opt/homebrew/Caskroom/miniforge/base/envs/kolkata_flood/lib/python3.13/site-packages (from rasterstats) (2.3.3)\n",
      "Requirement already satisfied: rasterio>=1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/kolkata_flood/lib/python3.13/site-packages (from rasterstats) (1.4.3)\n",
      "Collecting simplejson (from rasterstats)\n",
      "  Downloading simplejson-3.20.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: shapely in /opt/homebrew/Caskroom/miniforge/base/envs/kolkata_flood/lib/python3.13/site-packages (from rasterstats) (2.1.2)\n",
      "Requirement already satisfied: attrs in /opt/homebrew/Caskroom/miniforge/base/envs/kolkata_flood/lib/python3.13/site-packages (from rasterio>=1.0->rasterstats) (25.4.0)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniforge/base/envs/kolkata_flood/lib/python3.13/site-packages (from rasterio>=1.0->rasterstats) (2025.10.5)\n",
      "Requirement already satisfied: click-plugins in /opt/homebrew/Caskroom/miniforge/base/envs/kolkata_flood/lib/python3.13/site-packages (from rasterio>=1.0->rasterstats) (1.1.1.2)\n",
      "Requirement already satisfied: pyparsing in /opt/homebrew/Caskroom/miniforge/base/envs/kolkata_flood/lib/python3.13/site-packages (from rasterio>=1.0->rasterstats) (3.2.5)\n",
      "Downloading rasterstats-0.20.0-py3-none-any.whl (17 kB)\n",
      "Downloading fiona-1.10.1-cp313-cp313-macosx_11_0_arm64.whl (14.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading simplejson-3.20.2-cp313-cp313-macosx_11_0_arm64.whl (75 kB)\n",
      "Installing collected packages: simplejson, fiona, rasterstats\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [rasterstats]\u001b[0m [rasterstats]\n",
      "\u001b[1A\u001b[2KSuccessfully installed fiona-1.10.1 rasterstats-0.20.0 simplejson-3.20.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rasterstats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c83f4d5-a32c-439c-88aa-9711900bb8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
