{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-21T01:58:16.721689Z",
     "start_time": "2025-11-21T01:58:16.057993Z"
    }
   },
   "source": [
    "import ee\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize\n",
    "ee.Initialize(project=\"kolkata-flood-mapping\")\n",
    "\n",
    "# Fix: Check where you actually are\n",
    "print(f\"Current directory: {Path.cwd()}\")\n",
    "\n",
    "# Adjust based on where you are\n",
    "# If you're in notebooks/:\n",
    "if Path.cwd().name == 'notebooks':\n",
    "    PROJECT_ROOT = Path.cwd().parent\n",
    "    DATA_DIR = PROJECT_ROOT / 'data'\n",
    "# If you're already in project root:\n",
    "elif (Path.cwd() / 'data').exists():\n",
    "    PROJECT_ROOT = Path.cwd()\n",
    "    DATA_DIR = PROJECT_ROOT / 'data'\n",
    "# If you're somewhere else:\n",
    "else:\n",
    "    # Hardcode for safety\n",
    "    PROJECT_ROOT = Path('/Users/romitbasak/Projects/KolkataFloodMapping')\n",
    "    DATA_DIR = PROJECT_ROOT / 'data'\n",
    "\n",
    "SAR_DIR = DATA_DIR / 'sar'\n",
    "FEATURES_DIR = DATA_DIR / 'features'\n",
    "FEATURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SAR FEATURE EXTRACTION PIPELINE - SETUP\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"Paths verified:\")\n",
    "print(f\"  Project root: {PROJECT_ROOT}\")\n",
    "print(f\"  Data dir: {DATA_DIR}\")\n",
    "print(f\"  Wards file: {DATA_DIR / 'wards/kmc_wards_gee_ready.geojson'}\")\n",
    "print(f\"  Exists: {(DATA_DIR / 'wards/kmc_wards_gee_ready.geojson').exists()}\")\n",
    "\n",
    "# Load wards\n",
    "wards = gpd.read_file(DATA_DIR / 'wards/kmc_wards_gee_ready.geojson')\n",
    "wards['WARD'] = wards['WARD'].astype(str)\n",
    "\n",
    "kmc_bounds = wards.total_bounds\n",
    "kmc_bbox = ee.Geometry.Rectangle([kmc_bounds[0], kmc_bounds[1], kmc_bounds[2], kmc_bounds[3]])\n",
    "\n",
    "print(f\"\\n‚úì {len(wards)} wards loaded\")\n",
    "\n",
    "# Load dry dates\n",
    "rainfall_df = pd.read_csv(SAR_DIR / 'sar_5day_rainfall_nov_apr.csv')\n",
    "dry_dates_millis = rainfall_df[rainfall_df['is_dry']]['date_millis'].tolist()\n",
    "\n",
    "print(f\"‚úì {len(dry_dates_millis)} verified dry dates\")\n",
    "\n",
    "# Otsu threshold\n",
    "OTSU_S1 = -14.90\n",
    "print(f\"‚úì Otsu: {OTSU_S1:.2f} dB\")\n",
    "\n",
    "# Temporal periods\n",
    "periods = {\n",
    "    '2014-2016': ('2014-11-01', '2017-04-30'),\n",
    "    '2017-2019': ('2017-11-01', '2020-04-30'),\n",
    "    '2020-2022': ('2020-11-01', '2023-04-30'),\n",
    "    '2023-2025': ('2023-11-01', '2025-11-30')\n",
    "}\n",
    "\n",
    "def get_period_for_date(date_str):\n",
    "    for period_name, (start, end) in periods.items():\n",
    "        if start <= date_str <= end:\n",
    "            return period_name\n",
    "    return None\n",
    "\n",
    "print(f\"‚úì Period assignment ready\")\n",
    "print(f\"\\nüéØ Ready for SAR extraction!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: /Users/romitbasak/Projects/KolkataFloodMapping/data/sar\n",
      "============================================================\n",
      "SAR FEATURE EXTRACTION PIPELINE - SETUP\n",
      "============================================================\n",
      "Paths verified:\n",
      "  Project root: /Users/romitbasak/Projects/KolkataFloodMapping\n",
      "  Data dir: /Users/romitbasak/Projects/KolkataFloodMapping/data\n",
      "  Wards file: /Users/romitbasak/Projects/KolkataFloodMapping/data/wards/kmc_wards_gee_ready.geojson\n",
      "  Exists: True\n",
      "\n",
      "‚úì 141 wards loaded\n",
      "‚úì 565 verified dry dates\n",
      "‚úì Otsu: -14.90 dB\n",
      "‚úì Period assignment ready\n",
      "\n",
      "üéØ Ready for SAR extraction!\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T02:05:15.205642Z",
     "start_time": "2025-11-21T01:59:59.429167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"TEST: SAR FEATURE EXTRACTION (10 DATES)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load Sentinel-1\n",
    "s1_full = ee.ImageCollection('COPERNICUS/S1_GRD') \\\n",
    "    .filterBounds(kmc_bbox) \\\n",
    "    .filter(ee.Filter.eq('instrumentMode', 'IW')) \\\n",
    "    .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV')) \\\n",
    "    .filter(ee.Filter.eq('orbitProperties_pass', 'DESCENDING')) \\\n",
    "    .filterDate('2014-08-01', '2025-11-30') \\\n",
    "    .select('VV')\n",
    "\n",
    "all_s1_dates = s1_full.aggregate_array('system:time_start').distinct().getInfo()\n",
    "\n",
    "print(f\"‚úì Total S1 dates: {len(all_s1_dates)}\")\n",
    "\n",
    "# Sample 10 dates\n",
    "test_indices = np.linspace(0, len(all_s1_dates)-1, 10, dtype=int)\n",
    "test_dates = [all_s1_dates[i] for i in test_indices]\n",
    "\n",
    "print(f\"‚úì Testing 10 sample dates\\n\")\n",
    "\n",
    "# Test extraction (KMC-wide stats only, no ward geometries)\n",
    "test_results = []\n",
    "\n",
    "for i, date_millis in enumerate(test_dates, 1):\n",
    "    date_obj = datetime.fromtimestamp(date_millis / 1000)\n",
    "    date_str = date_obj.strftime('%Y-%m-%d')\n",
    "    period = get_period_for_date(date_str)\n",
    "\n",
    "    print(f\"  [{i}/10] {date_str} ({period})...\", end='', flush=True)\n",
    "\n",
    "    try:\n",
    "        # Get image\n",
    "        s1_img = s1_full.filter(ee.Filter.eq('system:time_start', int(date_millis))).first()\n",
    "\n",
    "        # Apply Otsu\n",
    "        vv_filt = s1_img.select('VV').focalMedian(100, 'circle', 'meters')\n",
    "        water = vv_filt.lt(OTSU_S1)\n",
    "\n",
    "        # Get KMC-wide statistics (no ward geometries)\n",
    "        stats = water.reduceRegion(\n",
    "            reducer=ee.Reducer.mean(),\n",
    "            geometry=kmc_bbox,\n",
    "            scale=10,\n",
    "            maxPixels=1e9\n",
    "        ).getInfo()\n",
    "\n",
    "        water_fraction = stats.get('VV', 0)\n",
    "\n",
    "        test_results.append({\n",
    "            'date': date_str,\n",
    "            'date_millis': date_millis,\n",
    "            'period': period,\n",
    "            'kmc_water_fraction': water_fraction\n",
    "        })\n",
    "\n",
    "        print(f\" ‚úì Water={water_fraction:.3f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" ‚ùå {e}\")\n",
    "\n",
    "test_df = pd.DataFrame(test_results)\n",
    "\n",
    "print(f\"\\n‚úÖ Test complete!\")\n",
    "print(f\"   Successful: {len(test_df)} / 10\")\n",
    "\n",
    "if len(test_df) > 0:\n",
    "    print(f\"\\nüìä Results:\")\n",
    "    print(test_df[['date', 'period', 'kmc_water_fraction']])\n",
    "\n",
    "    print(f\"\\nüéØ Pipeline validated!\")\n",
    "    print(f\"   Next: Process all dates with ward-level export approach\")\n",
    "    print(f\"   (Export SAR extent rasters, process locally like permanent masks)\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  All failed - need to debug\")"
   ],
   "id": "974357826bd359b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST: SAR FEATURE EXTRACTION (10 DATES)\n",
      "============================================================\n",
      "‚úì Total S1 dates: 792\n",
      "‚úì Testing 10 sample dates\n",
      "\n",
      "  [1/10] 2014-10-15 (None)... ‚úì Water=0.236\n",
      "  [2/10] 2017-05-13 (None)... ‚úì Water=0.074\n",
      "  [3/10] 2018-07-19 (2017-2019)... ‚úì Water=0.072\n",
      "  [4/10] 2019-09-19 (2017-2019)... ‚úì Water=0.209\n",
      "  [5/10] 2020-09-13 (None)... ‚úì Water=0.216\n",
      "  [6/10] 2021-09-01 (2020-2022)... ‚úì Water=0.072\n",
      "  [7/10] 2022-08-27 (2020-2022)... ‚úì Water=0.001\n",
      "  [8/10] 2023-10-09 (None)... ‚úì Water=0.066\n",
      "  [9/10] 2024-12-02 (2023-2025)... ‚úì Water=0.001\n",
      "  [10/10] 2020-07-21 (None)... ‚úì Water=0.192\n",
      "\n",
      "‚úÖ Test complete!\n",
      "   Successful: 10 / 10\n",
      "\n",
      "üìä Results:\n",
      "         date     period  kmc_water_fraction\n",
      "0  2014-10-15       None            0.235583\n",
      "1  2017-05-13       None            0.074075\n",
      "2  2018-07-19  2017-2019            0.072352\n",
      "3  2019-09-19  2017-2019            0.209226\n",
      "4  2020-09-13       None            0.216213\n",
      "5  2021-09-01  2020-2022            0.072243\n",
      "6  2022-08-27  2020-2022            0.000792\n",
      "7  2023-10-09       None            0.066254\n",
      "8  2024-12-02  2023-2025            0.001148\n",
      "9  2020-07-21       None            0.192009\n",
      "\n",
      "üéØ Pipeline validated!\n",
      "   Next: Process all dates with ward-level export approach\n",
      "   (Export SAR extent rasters, process locally like permanent masks)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T02:08:25.332561Z",
     "start_time": "2025-11-21T02:08:19.477370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"BATCH TEST: 100 DATES √ó 141 WARDS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"üéØ Strategy: Export to Drive, process locally\")\n",
    "print(\"   Avoids geometry issues + Mac-friendly!\")\n",
    "print(\"   Expected time: 1-2 hours\\n\")\n",
    "\n",
    "# Sample 100 dates (spread across all years)\n",
    "batch_size = 100\n",
    "batch_indices = np.linspace(0, len(all_s1_dates)-1, batch_size, dtype=int)\n",
    "batch_dates = [all_s1_dates[i] for i in batch_indices]\n",
    "\n",
    "print(f\"Selected {len(batch_dates)} dates\")\n",
    "print(f\"  Range: {datetime.fromtimestamp(batch_dates[0]/1000).strftime('%Y-%m-%d')} to {datetime.fromtimestamp(batch_dates[-1]/1000).strftime('%Y-%m-%d')}\")\n",
    "\n",
    "# Export water extent for each date\n",
    "print(f\"\\n‚öôÔ∏è  Exporting SAR water extent rasters to Drive...\")\n",
    "print(f\"   This will take 45-60 min (background processing)\")\n",
    "\n",
    "export_count = 0\n",
    "\n",
    "for date_millis in batch_dates[:10]:  # Start with just 10 for tonight\n",
    "    date_obj = datetime.fromtimestamp(date_millis / 1000)\n",
    "    date_str = date_obj.strftime('%Y%m%d')\n",
    "\n",
    "    # Get image\n",
    "    s1_img = s1_full.filter(ee.Filter.eq('system:time_start', int(date_millis))).first()\n",
    "\n",
    "    # Apply Otsu\n",
    "    vv_filt = s1_img.select('VV').focalMedian(100, 'circle', 'meters')\n",
    "    water = vv_filt.lt(OTSU_S1).toByte()  # 0 or 1\n",
    "\n",
    "    # Export\n",
    "    task = ee.batch.Export.image.toDrive(\n",
    "        image=water,\n",
    "        description=f'sar_water_{date_str}',\n",
    "        folder='Earth_Engine_Exports',\n",
    "        fileNamePrefix=f'sar_water_extent_{date_str}',\n",
    "        region=kmc_bbox.getInfo()['coordinates'],\n",
    "        scale=10,\n",
    "        maxPixels=1e10,\n",
    "        fileFormat='GeoTIFF'\n",
    "    )\n",
    "\n",
    "    task.start()\n",
    "    export_count += 1\n",
    "\n",
    "    if (export_count) % 5 == 0:\n",
    "        print(f\"  Started {export_count} exports...\")\n",
    "\n",
    "print(f\"\\n‚úÖ {export_count} exports started!\")\n",
    "print(f\"\\nüí° For tonight: Starting with 10 dates (validation)\")\n",
    "print(f\"   Tomorrow: Scale to 100, then full 1,989\")\n",
    "print(f\"\\n‚è∞ Check GEE Tasks in 45-60 min, then run next cell!\")"
   ],
   "id": "aaf6a7bf8e1e1bee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BATCH TEST: 100 DATES √ó 141 WARDS\n",
      "============================================================\n",
      "üéØ Strategy: Export to Drive, process locally\n",
      "   Avoids geometry issues + Mac-friendly!\n",
      "   Expected time: 1-2 hours\n",
      "\n",
      "Selected 100 dates\n",
      "  Range: 2014-10-15 to 2020-07-21\n",
      "\n",
      "‚öôÔ∏è  Exporting SAR water extent rasters to Drive...\n",
      "   This will take 45-60 min (background processing)\n",
      "  Started 5 exports...\n",
      "  Started 10 exports...\n",
      "\n",
      "‚úÖ 10 exports started!\n",
      "\n",
      "üí° For tonight: Starting with 10 dates (validation)\n",
      "   Tomorrow: Scale to 100, then full 1,989\n",
      "\n",
      "‚è∞ Check GEE Tasks in 45-60 min, then run next cell!\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T04:51:18.953204Z",
     "start_time": "2025-11-21T04:51:18.173856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"FIXED PROCESSING: CRS REPROJECTION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import rasterio\n",
    "from rasterio.mask import mask as rasterio_mask\n",
    "\n",
    "# Get SAR files\n",
    "sar_files = sorted(SAR_DIR.glob('sar_water_extent_*.tif'))\n",
    "\n",
    "print(f\"Processing {len(sar_files)} files...\")\n",
    "\n",
    "all_features = []\n",
    "\n",
    "for sar_file in sar_files:\n",
    "    # Extract date\n",
    "    date_str = sar_file.stem.split('_')[-1]  # YYYYMMDD\n",
    "    date_formatted = f\"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}\"\n",
    "    period = get_period_for_date(date_formatted)\n",
    "\n",
    "    with rasterio.open(sar_file) as src:\n",
    "        # Reproject wards to match raster CRS\n",
    "        wards_reprojected = wards.to_crs(src.crs)\n",
    "\n",
    "        # Process each ward\n",
    "        for idx, ward_row in wards_reprojected.iterrows():\n",
    "            ward_id = ward_row['WARD']\n",
    "            ward_geom = [ward_row['geometry'].__geo_interface__]\n",
    "\n",
    "            try:\n",
    "                # Mask to ward\n",
    "                out_img, _ = rasterio_mask(src, ward_geom, crop=True, filled=False)\n",
    "                data = out_img[0]\n",
    "\n",
    "                # Remove masked values\n",
    "                if hasattr(data, 'mask'):\n",
    "                    data = data[~data.mask]\n",
    "\n",
    "                data = data[np.isfinite(data)]\n",
    "\n",
    "                if len(data) > 0:\n",
    "                    water_pixels = (data == 1).sum()\n",
    "                    total_pixels = len(data)\n",
    "                    water_fraction = water_pixels / total_pixels\n",
    "\n",
    "                    all_features.append({\n",
    "                        'date': date_formatted,\n",
    "                        'ward_id': ward_id,\n",
    "                        'period': period,\n",
    "                        'sar_water_extent': water_fraction,\n",
    "                        'water_pixels': int(water_pixels),\n",
    "                        'total_pixels': int(total_pixels)\n",
    "                    })\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    print(f\"  ‚úì {date_formatted} ({period})\")\n",
    "\n",
    "# Create DataFrame\n",
    "sar_features = pd.DataFrame(all_features)\n",
    "\n",
    "print(f\"\\n‚úÖ Processed!\")\n",
    "print(f\"   Total rows: {len(sar_features)}\")\n",
    "print(f\"   Dates: {sar_features['date'].nunique()}\")\n",
    "print(f\"   Wards: {sar_features['ward_id'].nunique()}\")\n",
    "\n",
    "print(f\"\\nüìä Sample:\")\n",
    "print(sar_features.head(10))\n",
    "\n",
    "# Save\n",
    "sar_features.to_csv(FEATURES_DIR / 'sar_features_batch_0_test.csv', index=False)\n",
    "\n",
    "print(f\"\\n‚úì Saved: features/sar_features_batch_0_test.csv\")\n",
    "\n",
    "print(f\"\\nüéØ SUCCESS! Ready to scale to 50-date batches!\")"
   ],
   "id": "497e3551a047dc44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FIXED PROCESSING: CRS REPROJECTION\n",
      "============================================================\n",
      "Processing 10 files...\n",
      "  ‚úì 2014-10-15 (None)\n",
      "  ‚úì 2014-12-31 (2014-2016)\n",
      "  ‚úì 2015-04-18 (2014-2016)\n",
      "  ‚úì 2015-07-11 (2014-2016)\n",
      "  ‚úì 2015-12-26 (2014-2016)\n",
      "  ‚úì 2016-05-13 (2014-2016)\n",
      "  ‚úì 2016-07-24 (2014-2016)\n",
      "  ‚úì 2016-09-27 (2014-2016)\n",
      "  ‚úì 2016-12-08 (2014-2016)\n",
      "  ‚úì 2017-02-25 (2014-2016)\n",
      "\n",
      "‚úÖ Processed!\n",
      "   Total rows: 1410\n",
      "   Dates: 10\n",
      "   Wards: 141\n",
      "\n",
      "üìä Sample:\n",
      "         date ward_id period  sar_water_extent  water_pixels  total_pixels\n",
      "0  2014-10-15    93\\n   None               0.0             0         18689\n",
      "1  2014-10-15    61\\n   None               0.0             0          6427\n",
      "2  2014-10-15    86\\n   None               0.0             0          8875\n",
      "3  2014-10-15    90\\n   None               0.0             0         11458\n",
      "4  2014-10-15    26\\n   None               0.0             0          3520\n",
      "5  2014-10-15    72\\n   None               0.0             0          5787\n",
      "6  2014-10-15   134\\n   None               0.0             0          3812\n",
      "7  2014-10-15    99\\n   None               0.0             0          9107\n",
      "8  2014-10-15   125\\n   None               0.0             0         28813\n",
      "9  2014-10-15   118\\n   None               0.0             0          8484\n",
      "\n",
      "‚úì Saved: features/sar_features_batch_0_test.csv\n",
      "\n",
      "üéØ SUCCESS! Ready to scale to 50-date batches!\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T05:01:05.355011Z",
     "start_time": "2025-11-21T05:01:04.930604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"PROCESSING BATCH 1 (50 DATES)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import rasterio\n",
    "from rasterio.mask import mask as rasterio_mask\n",
    "\n",
    "sar_files = sorted(SAR_DIR.glob('sar_water_extent_*.tif'))\n",
    "\n",
    "print(f\"Found {len(sar_files)} files\")\n",
    "\n",
    "all_features = []\n",
    "\n",
    "for sar_file in sar_files:\n",
    "    date_str = sar_file.stem.split('_')[-1]\n",
    "    date_formatted = f\"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}\"\n",
    "    period = get_period_for_date(date_formatted)\n",
    "\n",
    "    with rasterio.open(sar_file) as src:\n",
    "        # Reproject wards to raster CRS\n",
    "        wards_proj = wards.to_crs(src.crs)\n",
    "\n",
    "        for idx, ward in wards_proj.iterrows():\n",
    "            ward_id = ward['WARD']\n",
    "\n",
    "            try:\n",
    "                out, _ = rasterio_mask(src, [ward['geometry'].__geo_interface__], crop=True, filled=False)\n",
    "                data = out[0]\n",
    "                data = data[~data.mask] if hasattr(data, 'mask') else data\n",
    "                data = data[np.isfinite(data)]\n",
    "\n",
    "                if len(data) > 0:\n",
    "                    water_pct = (data == 1).sum() / len(data)\n",
    "\n",
    "                    all_features.append({\n",
    "                        'date': date_formatted,\n",
    "                        'ward_id': ward_id,\n",
    "                        'period': period,\n",
    "                        'sar_water_extent': water_pct\n",
    "                    })\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    if len([f for f in all_features if f['date'] == date_formatted]) > 0:\n",
    "        print(f\"  ‚úì {date_formatted}\")\n",
    "\n",
    "df = pd.DataFrame(all_features)\n",
    "df['ward_id'] = df['ward_id'].astype(str).str.strip()\n",
    "\n",
    "print(f\"\\n‚úÖ Done! {len(df)} rows\")\n",
    "\n",
    "df.to_csv(FEATURES_DIR / 'sar_features_batch_1.csv', index=False)\n",
    "print(f\"‚úì Saved\")"
   ],
   "id": "2cb2a23cf02271c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BATCH 1: SERVER-SIDE PROCESSING (SMART!)\n",
      "============================================================\n",
      "üéØ Processing 50 dates √ó 141 wards in Earth Engine\n",
      "   Export: 1 CSV (not 50 rasters!)\n",
      "   Expected time: 10-15 min total\n",
      "\n",
      "Processing 50 dates:\n",
      "  Range: 2015-02-17 to 2016-11-02\n",
      "‚úì Ward FeatureCollection ready (141 wards)\n",
      "\n",
      "‚öôÔ∏è  Processing in Earth Engine...\n"
     ]
    },
    {
     "ename": "EEException",
     "evalue": "Collection.loadTable: Collection asset '/Users/romitbasak/Projects/KolkataFloodMapping/data/sar/temp_wards_simple.geojson' not found.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mHttpError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Caskroom/miniforge/base/envs/kolkata_flood/lib/python3.13/site-packages/ee/data.py:349\u001B[39m, in \u001B[36m_execute_cloud_call\u001B[39m\u001B[34m(call, num_retries)\u001B[39m\n\u001B[32m    348\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m349\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_retries\u001B[49m\u001B[43m=\u001B[49m\u001B[43mnum_retries\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    350\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m googleapiclient.errors.HttpError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Caskroom/miniforge/base/envs/kolkata_flood/lib/python3.13/site-packages/googleapiclient/_helpers.py:130\u001B[39m, in \u001B[36mpositional.<locals>.positional_decorator.<locals>.positional_wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    129\u001B[39m         logger.warning(message)\n\u001B[32m--> \u001B[39m\u001B[32m130\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Caskroom/miniforge/base/envs/kolkata_flood/lib/python3.13/site-packages/googleapiclient/http.py:938\u001B[39m, in \u001B[36mHttpRequest.execute\u001B[39m\u001B[34m(self, http, num_retries)\u001B[39m\n\u001B[32m    937\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m resp.status >= \u001B[32m300\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m938\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m HttpError(resp, content, uri=\u001B[38;5;28mself\u001B[39m.uri)\n\u001B[32m    939\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.postproc(resp, content)\n",
      "\u001B[31mHttpError\u001B[39m: <HttpError 400 when requesting https://earthengine.googleapis.com/v1/projects/kolkata-flood-mapping/value:compute?prettyPrint=false&alt=json returned \"Collection.loadTable: Collection asset '/Users/romitbasak/Projects/KolkataFloodMapping/data/sar/temp_wards_simple.geojson' not found.\". Details: \"Collection.loadTable: Collection asset '/Users/romitbasak/Projects/KolkataFloodMapping/data/sar/temp_wards_simple.geojson' not found.\">",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mEEException\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 54\u001B[39m\n\u001B[32m     47\u001B[39m ward_stats = water.reduceRegions(\n\u001B[32m     48\u001B[39m     collection=wards_ee,\n\u001B[32m     49\u001B[39m     reducer=ee.Reducer.mean(),\n\u001B[32m     50\u001B[39m     scale=\u001B[32m10\u001B[39m\n\u001B[32m     51\u001B[39m )\n\u001B[32m     53\u001B[39m \u001B[38;5;66;03m# Get results\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m54\u001B[39m stats_data = \u001B[43mward_stats\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgetInfo\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     56\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m feature \u001B[38;5;129;01min\u001B[39;00m stats_data[\u001B[33m'\u001B[39m\u001B[33mfeatures\u001B[39m\u001B[33m'\u001B[39m]:\n\u001B[32m     57\u001B[39m     props = feature[\u001B[33m'\u001B[39m\u001B[33mproperties\u001B[39m\u001B[33m'\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Caskroom/miniforge/base/envs/kolkata_flood/lib/python3.13/site-packages/ee/collection.py:588\u001B[39m, in \u001B[36mCollection.getInfo\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    575\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mgetInfo\u001B[39m(\u001B[38;5;28mself\u001B[39m) -> Any | \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    576\u001B[39m \u001B[38;5;250m  \u001B[39m\u001B[33;03m\"\"\"Returns all the known information about this collection.\u001B[39;00m\n\u001B[32m    577\u001B[39m \n\u001B[32m    578\u001B[39m \u001B[33;03m  This function makes a REST call to to retrieve all the known information\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    586\u001B[39m \u001B[33;03m         properties.\u001B[39;00m\n\u001B[32m    587\u001B[39m \u001B[33;03m  \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m588\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mgetInfo\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Caskroom/miniforge/base/envs/kolkata_flood/lib/python3.13/site-packages/ee/computedobject.py:107\u001B[39m, in \u001B[36mComputedObject.getInfo\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    101\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mgetInfo\u001B[39m(\u001B[38;5;28mself\u001B[39m) -> Any | \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    102\u001B[39m \u001B[38;5;250m  \u001B[39m\u001B[33;03m\"\"\"Fetch and return information about this object.\u001B[39;00m\n\u001B[32m    103\u001B[39m \n\u001B[32m    104\u001B[39m \u001B[33;03m  Returns:\u001B[39;00m\n\u001B[32m    105\u001B[39m \u001B[33;03m    The object can evaluate to anything.\u001B[39;00m\n\u001B[32m    106\u001B[39m \u001B[33;03m  \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m107\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdata\u001B[49m\u001B[43m.\u001B[49m\u001B[43mcomputeValue\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Caskroom/miniforge/base/envs/kolkata_flood/lib/python3.13/site-packages/ee/data.py:1064\u001B[39m, in \u001B[36mcomputeValue\u001B[39m\u001B[34m(obj)\u001B[39m\n\u001B[32m   1061\u001B[39m body = {\u001B[33m'\u001B[39m\u001B[33mexpression\u001B[39m\u001B[33m'\u001B[39m: serializer.encode(obj, for_cloud_api=\u001B[38;5;28;01mTrue\u001B[39;00m)}\n\u001B[32m   1062\u001B[39m _maybe_populate_workload_tag(body)\n\u001B[32m-> \u001B[39m\u001B[32m1064\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_execute_cloud_call\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1065\u001B[39m \u001B[43m    \u001B[49m\u001B[43m_get_cloud_projects\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1066\u001B[39m \u001B[43m    \u001B[49m\u001B[43m.\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1067\u001B[39m \u001B[43m    \u001B[49m\u001B[43m.\u001B[49m\u001B[43mcompute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbody\u001B[49m\u001B[43m=\u001B[49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mproject\u001B[49m\u001B[43m=\u001B[49m\u001B[43m_get_projects_path\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprettyPrint\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m   1068\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m[\u001B[33m'\u001B[39m\u001B[33mresult\u001B[39m\u001B[33m'\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/homebrew/Caskroom/miniforge/base/envs/kolkata_flood/lib/python3.13/site-packages/ee/data.py:351\u001B[39m, in \u001B[36m_execute_cloud_call\u001B[39m\u001B[34m(call, num_retries)\u001B[39m\n\u001B[32m    349\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m call.execute(num_retries=num_retries)\n\u001B[32m    350\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m googleapiclient.errors.HttpError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m--> \u001B[39m\u001B[32m351\u001B[39m   \u001B[38;5;28;01mraise\u001B[39;00m _translate_cloud_exception(e)\n",
      "\u001B[31mEEException\u001B[39m: Collection.loadTable: Collection asset '/Users/romitbasak/Projects/KolkataFloodMapping/data/sar/temp_wards_simple.geojson' not found."
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T05:07:19.932816Z",
     "start_time": "2025-11-21T05:07:19.898741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"UPLOADING WARDS TO EARTH ENGINE (ONE-TIME)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"üéØ Strategy: Upload wards as GEE asset\")\n",
    "print(\"   Then ALL processing can be server-side!\")\n",
    "print(\"   Future users just reference the asset\\n\")\n",
    "\n",
    "# Simplify geometries for faster processing\n",
    "wards_for_gee = wards.copy()\n",
    "wards_for_gee['geometry'] = wards_for_gee.geometry.simplify(0.0001)\n",
    "wards_for_gee = wards_for_gee[['WARD', 'geometry']]\n",
    "wards_for_gee['WARD'] = wards_for_gee['WARD'].astype(str)\n",
    "\n",
    "# Save as GeoJSON for upload\n",
    "gee_wards_file = DATA_DIR / 'wards/kmc_wards_for_gee_asset.geojson'\n",
    "wards_for_gee.to_file(gee_wards_file, driver='GeoJSON')\n",
    "\n",
    "print(f\"‚úì Saved simplified wards: {gee_wards_file}\")\n",
    "\n",
    "print(f\"\\nüì§ UPLOAD TO GEE:\")\n",
    "print(f\"\"\"\n",
    "Option 1: GEE Code Editor (Easy):\n",
    "  1. Go to: https://code.earthengine.google.com/\n",
    "  2. Click 'Assets' tab (left panel)\n",
    "  3. Click 'NEW' ‚Üí 'Shape files' (or Table upload)\n",
    "  4. Upload: {gee_wards_file}\n",
    "  5. Asset name: 'users/YOUR_USERNAME/kmc_wards_141'\n",
    "  6. Wait 2-5 min for ingestion\n",
    "  7. Copy asset path\n",
    "\n",
    "Option 2: Python API (if you prefer):\n",
    "  # Requires earthengine-api\n",
    "  # More complex, but can be scripted\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\n‚è∞ While upload processes:\")\n",
    "print(f\"   Let those raster exports finish (use them for Batch 1)\")\n",
    "print(f\"   From Batch 2 onwards: Use asset-based server-side approach\")\n",
    "\n",
    "print(f\"\\nüí° HYBRID TONIGHT:\")\n",
    "print(f\"   Batch 1: Use the 50 raster exports (already running)\")\n",
    "print(f\"   Batch 2+: Server-side with uploaded asset (much faster!)\")"
   ],
   "id": "63a341c57bfa6bf8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "UPLOADING WARDS TO EARTH ENGINE (ONE-TIME)\n",
      "============================================================\n",
      "üéØ Strategy: Upload wards as GEE asset\n",
      "   Then ALL processing can be server-side!\n",
      "   Future users just reference the asset\n",
      "\n",
      "‚úì Saved simplified wards: /Users/romitbasak/Projects/KolkataFloodMapping/data/wards/kmc_wards_for_gee_asset.geojson\n",
      "\n",
      "üì§ UPLOAD TO GEE:\n",
      "\n",
      "Option 1: GEE Code Editor (Easy):\n",
      "  1. Go to: https://code.earthengine.google.com/\n",
      "  2. Click 'Assets' tab (left panel)\n",
      "  3. Click 'NEW' ‚Üí 'Shape files' (or Table upload)\n",
      "  4. Upload: /Users/romitbasak/Projects/KolkataFloodMapping/data/wards/kmc_wards_for_gee_asset.geojson\n",
      "  5. Asset name: 'users/YOUR_USERNAME/kmc_wards_141'\n",
      "  6. Wait 2-5 min for ingestion\n",
      "  7. Copy asset path\n",
      "\n",
      "Option 2: Python API (if you prefer):\n",
      "  # Requires earthengine-api\n",
      "  # More complex, but can be scripted\n",
      "\n",
      "\n",
      "‚è∞ While upload processes:\n",
      "   Let those raster exports finish (use them for Batch 1)\n",
      "   From Batch 2 onwards: Use asset-based server-side approach\n",
      "\n",
      "üí° HYBRID TONIGHT:\n",
      "   Batch 1: Use the 50 raster exports (already running)\n",
      "   Batch 2+: Server-side with uploaded asset (much faster!)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T05:15:49.463876Z",
     "start_time": "2025-11-21T05:15:48.352251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"TESTING EXISTING GEE WARD ASSET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Try loading the existing asset\n",
    "# Common asset names from your files:\n",
    "asset_options = [\n",
    "    'users/romitbasak/kmc_wards_141',\n",
    "    'users/romitbasak/kmc_wards',\n",
    "    'projects/kolkata-flood-mapping/assets/kmc_wards_141',\n",
    "    'projects/kolkata-flood-mapping/assets/kmc_wards'\n",
    "]\n",
    "\n",
    "for asset_path in asset_options:\n",
    "    try:\n",
    "        print(f\"\\nTrying: {asset_path}...\", end='')\n",
    "        wards_ee = ee.FeatureCollection(asset_path)\n",
    "        count = wards_ee.size().getInfo()\n",
    "\n",
    "        print(f\" ‚úÖ FOUND!\")\n",
    "        print(f\"  Wards: {count}\")\n",
    "\n",
    "        # Quick test - get first ward\n",
    "        first = wards_ee.first().getInfo()\n",
    "        print(f\"  Properties: {list(first['properties'].keys())}\")\n",
    "\n",
    "        print(f\"\\nüéØ USE THIS ASSET:\")\n",
    "        print(f\"   WARD_ASSET = '{asset_path}'\")\n",
    "\n",
    "        break\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" ‚ùå\")\n",
    "\n",
    "print(f\"\\nIf none worked, we need to:\")\n",
    "print(f\"  1. Delete old asset in GEE Assets tab\")\n",
    "print(f\"  2. Re-upload the shapefile\")"
   ],
   "id": "f43419f267aa7c27",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TESTING EXISTING GEE WARD ASSET\n",
      "============================================================\n",
      "\n",
      "Trying: users/romitbasak/kmc_wards_141... ‚ùå\n",
      "\n",
      "Trying: users/romitbasak/kmc_wards... ‚ùå\n",
      "\n",
      "Trying: projects/kolkata-flood-mapping/assets/kmc_wards_141... ‚ùå\n",
      "\n",
      "Trying: projects/kolkata-flood-mapping/assets/kmc_wards... ‚úÖ FOUND!\n",
      "  Wards: 141\n",
      "  Properties: ['WARD']\n",
      "\n",
      "üéØ USE THIS ASSET:\n",
      "   WARD_ASSET = 'projects/kolkata-flood-mapping/assets/kmc_wards'\n",
      "\n",
      "If none worked, we need to:\n",
      "  1. Delete old asset in GEE Assets tab\n",
      "  2. Re-upload the shapefile\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T05:41:43.696462Z",
     "start_time": "2025-11-21T05:17:06.340402Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"SERVER-SIDE SAR PROCESSING - BATCH 1 (50 DATES)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Load ward asset\n",
    "WARD_ASSET = 'projects/kolkata-flood-mapping/assets/kmc_wards'\n",
    "wards_ee = ee.FeatureCollection(WARD_ASSET)\n",
    "\n",
    "print(f\"‚úì Ward asset loaded: {wards_ee.size().getInfo()} wards\")\n",
    "\n",
    "# Select 50 dates for Batch 1\n",
    "BATCH_SIZE = 50\n",
    "batch_1_indices = np.linspace(10, 60, BATCH_SIZE, dtype=int)\n",
    "batch_1_dates = [all_s1_dates[i] for i in batch_1_indices]\n",
    "\n",
    "print(f\"\\nüìÖ Batch 1: 50 dates\")\n",
    "print(f\"   Range: {datetime.fromtimestamp(batch_1_dates[0]/1000).strftime('%Y-%m-%d')} to {datetime.fromtimestamp(batch_1_dates[-1]/1000).strftime('%Y-%m-%d')}\")\n",
    "print(f\"   Expected time: 15-20 min (all server-side!)\")\n",
    "\n",
    "# Process all dates\n",
    "print(f\"\\n‚öôÔ∏è  Processing 50 dates √ó 141 wards in Earth Engine...\")\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for i, date_millis in enumerate(batch_1_dates, 1):\n",
    "    date_obj = datetime.fromtimestamp(date_millis / 1000)\n",
    "    date_str = date_obj.strftime('%Y-%m-%d')\n",
    "    period = get_period_for_date(date_str)\n",
    "\n",
    "    # Get image and detect water\n",
    "    s1_img = s1_full.filter(ee.Filter.eq('system:time_start', int(date_millis))).first()\n",
    "    vv_filt = s1_img.select('VV').focalMedian(100, 'circle', 'meters')\n",
    "    water = vv_filt.lt(OTSU_S1)\n",
    "\n",
    "    # Calculate statistics per ward (server-side!)\n",
    "    ward_stats = water.reduceRegions(\n",
    "        collection=wards_ee,\n",
    "        reducer=ee.Reducer.mean(),\n",
    "        scale=10\n",
    "    )\n",
    "\n",
    "    # Get results\n",
    "    stats = ward_stats.getInfo()\n",
    "\n",
    "    for feature in stats['features']:\n",
    "        props = feature['properties']\n",
    "        all_results.append({\n",
    "            'date': date_str,\n",
    "            'ward_id': str(props.get('WARD', '')),\n",
    "            'period': period,\n",
    "            'sar_water_extent': props.get('mean', 0)\n",
    "        })\n",
    "\n",
    "    if i % 5 == 0:\n",
    "        print(f\"  [{i}/50] {date_str} ({period})...\")\n",
    "\n",
    "# Create DataFrame\n",
    "batch_1_df = pd.DataFrame(all_results)\n",
    "batch_1_df['ward_id'] = batch_1_df['ward_id'].astype(str).str.strip()\n",
    "\n",
    "print(f\"\\n‚úÖ Batch 1 complete!\")\n",
    "print(f\"   Rows: {len(batch_1_df)} (50 dates √ó 141 wards = 7,050)\")\n",
    "print(f\"   Dates: {batch_1_df['date'].nunique()}\")\n",
    "print(f\"   Wards: {batch_1_df['ward_id'].nunique()}\")\n",
    "\n",
    "# Save\n",
    "batch_1_df.to_csv(FEATURES_DIR / 'sar_features_batch_1.csv', index=False)\n",
    "\n",
    "print(f\"\\n‚úì Saved: features/sar_features_batch_1.csv\")\n",
    "\n",
    "print(f\"\\nüéØ 100% SERVER-SIDE!\")\n",
    "print(f\"   No downloads, no disk space, reproducible!\")\n",
    "print(f\"\\n‚è≠Ô∏è  Ready to scale to full 1,290 dates!\")"
   ],
   "id": "922db657c1d78d18",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SERVER-SIDE SAR PROCESSING - BATCH 1 (50 DATES)\n",
      "============================================================\n",
      "‚úì Ward asset loaded: 141 wards\n",
      "\n",
      "üìÖ Batch 1: 50 dates\n",
      "   Range: 2015-02-17 to 2016-11-02\n",
      "   Expected time: 15-20 min (all server-side!)\n",
      "\n",
      "‚öôÔ∏è  Processing 50 dates √ó 141 wards in Earth Engine...\n",
      "  [5/50] 2015-04-01 (2014-2016)...\n",
      "  [10/50] 2015-06-05 (2014-2016)...\n",
      "  [15/50] 2015-07-23 (2014-2016)...\n",
      "  [20/50] 2015-11-27 (2014-2016)...\n",
      "  [25/50] 2016-02-12 (2014-2016)...\n",
      "  [30/50] 2016-05-13 (2014-2016)...\n",
      "  [35/50] 2016-06-30 (2014-2016)...\n",
      "  [40/50] 2016-08-10 (2014-2016)...\n",
      "  [45/50] 2016-09-15 (2014-2016)...\n",
      "  [50/50] 2016-11-02 (2014-2016)...\n",
      "\n",
      "‚úÖ Batch 1 complete!\n",
      "   Rows: 7050 (50 dates √ó 141 wards = 7,050)\n",
      "   Dates: 50\n",
      "   Wards: 141\n",
      "\n",
      "‚úì Saved: features/sar_features_batch_1.csv\n",
      "\n",
      "üéØ 100% SERVER-SIDE!\n",
      "   No downloads, no disk space, reproducible!\n",
      "\n",
      "‚è≠Ô∏è  Ready to scale to full 1,290 dates!\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
